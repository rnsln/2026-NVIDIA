{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f70ff2-492a-41a4-97db-5da6d5775cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3992e-c095-4bd7-9f14-60abd0740b64",
   "metadata": {},
   "source": [
    "# Quantum Enhanced Optimization for Radar and Communications Applications \n",
    "\n",
    "\n",
    "The Low Autocorrelation Binary Sequences (LABS) is an important and challenging optimization problem with applications related to radar, telecommunications, and other signal related applications. This CUDA-Q Academic module will focus on a clever quantum-enhanced hybrid method developed in a collaboration between Kipu Quantum, University of the Basque Country EHU, and NVIDIA for solving the LABS problem. (This notebook was jointly developed with input from all collaborators.)\n",
    "\n",
    "Other CUDA-Q Academic modules like [Divide and Conquer MaxCut QAOA](https://github.com/NVIDIA/cuda-q-academic/tree/main/qaoa-for-max-cut) and [Quantum Finance](https://github.com/NVIDIA/cuda-q-academic/blob/main/quantum-applications-to-finance/03_qchop.ipynb), demonstrate how quantum computing can be used outright to solve optimization problems. This notebook demonstrates a slightly different approach. Rather than considering QPUs as the tool to produce the final answer, it demonstrates how quantum can be used to enhance the effectiveness of leading classical methods.  \n",
    "\n",
    "The benefits of such an approach were highlighted in [Scaling advantage with quantum-enhanced memetic tabu search for LABS](https://arxiv.org/html/2511.04553v1).  This notebook, co-created with the authors of the paper, will allow you to explore the findings of their research and write your own CUDA-Q code that builds a representative quantum-enhanced workflow for solving the LABS problem. Moreover, it will introduce advancements in counteradiabatic optimization techniques on which reduce the quantum resources required to run on a QPU.\n",
    "\n",
    "**Prerequisites:** This lab assumes you have a basic knowledge of quantum computing, including operators, gates, etc.  For a refresher on some of these topics, explore the [Quick start to Quantum](https://github.com/NVIDIA/cuda-q-academic/tree/main/quick-start-to-quantum) series.\n",
    "\n",
    "**In this lab you will:**\n",
    "* 1. Understand the LABS problem and its relation ot radar and communication applications.\n",
    "* 2. Solve LABS classically with memetic tabu search and learn about the limitations of such methods.\n",
    "* 3. Code a couteradiabatic algorithm using CUDA-Q to produce approximate solutions to the LABS problem.\n",
    "* 4. Use the CUDA-Q results to seed your tabu search and understand the potential benefits of this approach.\n",
    "\n",
    "\n",
    "**Terminology you will use:**\n",
    "* Low autocorrelation of binary sequences (LABS)\n",
    "* counteradiabatic optimization\n",
    "* memetic-tabu search\n",
    "\n",
    "**CUDA-Q Syntax you will use:**\n",
    "* cudaq.sample()\n",
    "* @cudaq.kernel\n",
    "* ry(), rx(), rz(), x(), h() \n",
    "* x.ctrl()\n",
    "\n",
    "Run the code below to initialize the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc407dd-113d-485c-88db-7ddbad344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import auxiliary_files.labs_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e821a8-47b4-4e5b-a713-4e1babada01f",
   "metadata": {},
   "source": [
    "## The LABS problem and applications\n",
    "\n",
    "The **Low Autocorrelation Binary Sequences (LABS)** problem is fundamental to many applications, but originated with applications to radar. \n",
    "\n",
    "Consider a radar that monitors airport traffic.  The radar signal sent to detect incoming planes must have as much range as possible to ensure safe approaches are planned well in advance.  The range of a radar signal can be increased by sending a longer pulse.  However, in order to differentiate between multiple objects, pulses need to be short to provide high resolution. So, how do you handle situations where you need both?\n",
    "\n",
    "One solution is a technique called pulse compression.  The idea is to send a long signal, but vary the phase at regular intervals such that the resolution is increased. Generally, the initial signal will encode a binary sequence of phase shifts, where each interval corresponds to a signal with a 0 or 180 degree phase shift. \n",
    "\n",
    "The tricky part is selecting an optimal encoding sequence.  When the signal returns, it is fed into a matched filter with the hope that a singular sharp peak will appear, indicating clear detection.  The autocorrelation of the original signal, or how similar the signal is to itself,  determines if a single peak or a messier signal with sidelobes will be detected. A signal should have high autocorrelation when overlayed on top of itself, but low autocorrelation when shifted with a lag. \n",
    "\n",
    "Consider the image below.  The signal on the left has a crisp single peak while the single on the right produces many undesirable sidelobes which can inhibit clear detection.  \n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/radar.png\" width=\"800\">\n",
    "\n",
    "\n",
    "So, how do you select a good signal?   This is where LABS comes in, defining these questions as a binary optimization problem. Given a binary sequence of length $N$, $(s_1 \\cdots s_N) \\in {\\pm 1}^N$, the goal is to minimize the following objective function.\n",
    "\n",
    "$$ E(s) = \\sum_{k=1}^{N-1} C_k^2 $$\n",
    "\n",
    "Where $C_k$ is defined as. \n",
    "\n",
    " $$C_k= \\sum_{i=1}^{N-k} s_is_{i+k}$$\n",
    "\n",
    "\n",
    "So, each $C_k$ computes how similar the original signal is to the shifted one for each offset value $k$.  To explore this more, try the interactive widget linked [here](https://nvidia.github.io/cuda-q-academic/interactive_widgets/labs_visualization.html).  See if you can select a very good and very poor sequence and see the difference for the case of $N=7$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa6dff-0fee-4251-a006-76d6ad426116",
   "metadata": {},
   "source": [
    "## Classical Solution of the LABS problem\n",
    "\n",
    "The LABS problem is tricky to solve for a few reasons. First, the configuration space grows exponentially.  Second, underlying symmetries of the problem result in many degeneracies in the optimization landscape severely inhibiting local search methods. \n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 1:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "Using the widget above, try to find some of the symmetries for the LABS problem. That is, for a fixed bitstring length, can you find patterns to produce the same energy with different pulse patterns. \n",
    "</div>\n",
    "\n",
    "The best known performance for a classical optimization technique is Memetic Tabu search (MTS) which exhibits a scaling of $O(1.34^N)$.  The MTS algorithm is depicted below.  It begins with a randomly selected population of bitstrings and finds the best solution from them.  Then, a child is selected by sampling directly from or combining multiple bitstrings from the population.  The child is mutated with probability $p_{mutate}$ and then input to a tabu search, which performs a modified greedy local search starting from the child bitstring.  If the result is better than the best in the population, it is updated as the new leader and randomly replaces a  bitstring in the population.\n",
    "\n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/mts_algorithm.png\" width=\"500\">\n",
    "\n",
    "Such an approach is fast, parallelizable, and allows for exploration with improved searching of the solution landscape.  \n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 2:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "Before exploring any quantum approach, get a sense for how MTS works by coding it yourself based generally on the figure above. Algorithms for the combine and mutate steps are provided below as used in the paper. You may need to research more specific details of the process, especially for how tabu search is performed. The MTS procedure should output and optimal bitstring and its energy.  Also, write a function to visualize the results including the energy distribution of the final population.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/combine_mutate.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac14b19-d8ef-498f-b6db-1cf205024b5b",
   "metadata": {},
   "source": [
    "## Exercise 1: LABS Problem Definition and Symmetries\n",
    "\n",
    "We study the **Low Autocorrelation Binary Sequence (LABS)** problem, where the goal\n",
    "is to find a binary sequence\n",
    "\\(\\mathbf{s} = (s_1, \\dots, s_N)\\) with \\(s_i \\in \\{-1, +1\\}\\) that minimizes\n",
    "aperiodic autocorrelation across all non-zero lags.\n",
    "\n",
    "The LABS energy is defined as:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{s}) = \\sum_{k=1}^{N-1} C_k(\\mathbf{s})^2,\n",
    "\\quad\n",
    "C_k(\\mathbf{s}) = \\sum_{i=1}^{N-k} s_i s_{i+k}.\n",
    "$$\n",
    "\n",
    "This objective exhibits several **exact symmetries**, including:\n",
    "- Global sign flip: \\(\\mathbf{s} \\mapsto -\\mathbf{s}\\)\n",
    "- Sequence reversal\n",
    "- Reversal combined with sign flip\n",
    "\n",
    "These invariances imply that many distinct sequences share the same energy.\n",
    "We exploit these properties as **self-validation checks** for our\n",
    "`compute_energy` implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d15a57-be9e-4fd8-a2b3-d2363b4aadea",
   "metadata": {},
   "source": [
    "## LABS Problem Formulation\n",
    "\n",
    "A **Low Autocorrelation Binary Sequence (LABS)** of length \\(N\\) is a sequence\n",
    "\\(\\mathbf{s} = (s_1, s_2, \\ldots, s_N)\\) where each element is binary in the\n",
    "\\(\\pm 1\\) representation:\n",
    "\n",
    "$$\n",
    "s_i \\in \\{-1, +1\\}, \\quad i = 1, \\ldots, N.\n",
    "$$\n",
    "\n",
    "For each lag \\(k = 1, 2, \\ldots, N-1\\), define the (aperiodic) autocorrelation:\n",
    "\n",
    "$$\n",
    "C_k(\\mathbf{s}) = \\sum_{i=1}^{N-k} s_i s_{i+k}.\n",
    "$$\n",
    "\n",
    "The LABS objective (energy) is:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{s}) = \\sum_{k=1}^{N-1} \\left(C_k(\\mathbf{s})\\right)^2.\n",
    "$$\n",
    "\n",
    "The optimization problem is therefore:\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^\\star\n",
    "= \\arg\\min_{\\mathbf{s} \\in \\{-1,+1\\}^N} E(\\mathbf{s}).\n",
    "$$\n",
    "\n",
    "Lower energy corresponds to lower autocorrelation across all lags, meaning the\n",
    "sequence is less predictable under shifts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66c41f-aa48-432d-8f33-96822e400cf5",
   "metadata": {},
   "source": [
    "## Exercise 2: Classical Memetic Tabu Search (MTS)\n",
    "\n",
    "Before introducing any quantum enhancement, we implement a **classical baseline**\n",
    "based on Memetic Tabu Search (MTS), following the reference paper.\n",
    "\n",
    "MTS combines:\n",
    "- A population-based genetic framework\n",
    "- Local refinement via tabu search\n",
    "- Controlled mutation to maintain diversity\n",
    "\n",
    "Each generation consists of:\n",
    "1. Selecting parent sequences from the population\n",
    "2. Recombining parents via one-point crossover\n",
    "3. Applying random bit flips with probability \\(p_{\\text{mut}}\\)\n",
    "4. Refining the child using tabu-guided local search\n",
    "5. Updating the population if improvement is found\n",
    "\n",
    "The algorithm returns the best sequence found and its corresponding LABS energy.\n",
    "This classical baseline is later used for both validation and benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c9a3f-565c-49ab-9903-0aa9a508722c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO - Write code to perform MTS\n",
    "\"\"\"\n",
    "Memetic Tabu Search (MTS) for the LABS Problem\n",
    "===============================================\n",
    "Implements the MTS algorithm as described in the paper:\n",
    "\"Scaling advantage with quantum-enhanced memetic tabu search for LABS\"\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LABS Energy Functions\n",
    "# ============================================================================\n",
    "\n",
    "def compute_Ck(s: np.ndarray, k: int) -> int:\n",
    "    \"\"\"\n",
    "    Compute the k-th autocorrelation coefficient C_k.\n",
    "    C_k = sum_{i=1}^{N-k} s_i * s_{i+k}\n",
    "    \n",
    "    Args:\n",
    "        s: Binary sequence of +1/-1 values\n",
    "        k: Lag offset (1 to N-1)\n",
    "    \n",
    "    Returns:\n",
    "        Autocorrelation value C_k\n",
    "    \"\"\"\n",
    "    N = len(s)\n",
    "    return int(np.sum(s[:N-k] * s[k:]))\n",
    "\n",
    "\n",
    "def compute_energy(s: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compute the LABS energy E(s) = sum_{k=1}^{N-1} C_k^2\n",
    "    \n",
    "    Args:\n",
    "        s: Binary sequence of +1/-1 values\n",
    "    \n",
    "    Returns:\n",
    "        Energy value (lower is better)\n",
    "    \"\"\"\n",
    "    N = len(s)\n",
    "    energy = 0\n",
    "    for k in range(1, N):\n",
    "        Ck = compute_Ck(s, k)\n",
    "        energy += Ck * Ck\n",
    "    return energy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MTS Helper Functions: Combine and Mutate\n",
    "# ============================================================================\n",
    "\n",
    "def combine(p1: np.ndarray, p2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Combine two parent sequences using single-point crossover.\n",
    "    Algorithm 3, Line 1-3 from the paper.\n",
    "    \n",
    "    Args:\n",
    "        p1: First parent sequence\n",
    "        p2: Second parent sequence\n",
    "    \n",
    "    Returns:\n",
    "        Child sequence\n",
    "    \"\"\"\n",
    "    N = len(p1)\n",
    "    # Choose cut point k uniformly from {1, ..., N-1}\n",
    "    k = np.random.randint(1, N)\n",
    "    # Return p1[0:k] || p2[k:N]\n",
    "    child = np.concatenate([p1[:k], p2[k:]])\n",
    "    return child\n",
    "\n",
    "\n",
    "def mutate(s: np.ndarray, p_mut: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mutate a sequence by flipping each bit with probability p_mut.\n",
    "    Algorithm 3, Line 4-8 from the paper.\n",
    "    \n",
    "    Args:\n",
    "        s: Input sequence\n",
    "        p_mut: Mutation probability per bit\n",
    "    \n",
    "    Returns:\n",
    "        Mutated sequence\n",
    "    \"\"\"\n",
    "    s = s.copy()\n",
    "    for i in range(len(s)):\n",
    "        if np.random.random() < p_mut:\n",
    "            s[i] = -s[i]  # Flip: +1 -> -1 or -1 -> +1\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Tabu Search Implementation\n",
    "# ============================================================================\n",
    "\n",
    "def tabu_search(s: np.ndarray, max_iter: int = 100, tabu_tenure: int = 7) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Perform Tabu Search starting from sequence s.\n",
    "    \n",
    "    Tabu Search is a local search that:\n",
    "    1. At each step, evaluates all single-bit-flip neighbors\n",
    "    2. Selects the best non-tabu move (or best aspiration move if it beats global best)\n",
    "    3. Adds the flipped position to tabu list to avoid cycling\n",
    "    \n",
    "    Args:\n",
    "        s: Starting sequence\n",
    "        max_iter: Maximum iterations\n",
    "        tabu_tenure: How long a move stays in tabu list\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (best_sequence, best_energy)\n",
    "    \"\"\"\n",
    "    N = len(s)\n",
    "    current = s.copy()\n",
    "    current_energy = compute_energy(current)\n",
    "    \n",
    "    best = current.copy()\n",
    "    best_energy = current_energy\n",
    "    \n",
    "    # Tabu list: stores the iteration when each position becomes non-tabu\n",
    "    tabu_list = np.zeros(N, dtype=int)\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        best_neighbor_energy = float('inf')\n",
    "        best_flip_pos = -1\n",
    "        \n",
    "        # Evaluate all single-bit-flip neighbors\n",
    "        for i in range(N):\n",
    "            # Create neighbor by flipping bit i\n",
    "            neighbor = current.copy()\n",
    "            neighbor[i] = -neighbor[i]\n",
    "            neighbor_energy = compute_energy(neighbor)\n",
    "            \n",
    "            # Check if move is tabu\n",
    "            is_tabu = tabu_list[i] > iteration\n",
    "            \n",
    "            # Aspiration criterion: accept if it beats global best\n",
    "            aspiration = neighbor_energy < best_energy\n",
    "            \n",
    "            if (not is_tabu or aspiration) and neighbor_energy < best_neighbor_energy:\n",
    "                best_neighbor_energy = neighbor_energy\n",
    "                best_flip_pos = i\n",
    "        \n",
    "        # If no improving move found, break\n",
    "        if best_flip_pos == -1:\n",
    "            break\n",
    "        \n",
    "        # Make the move\n",
    "        current[best_flip_pos] = -current[best_flip_pos]\n",
    "        current_energy = best_neighbor_energy\n",
    "        \n",
    "        # Add to tabu list\n",
    "        tabu_list[best_flip_pos] = iteration + tabu_tenure\n",
    "        \n",
    "        # Update global best\n",
    "        if current_energy < best_energy:\n",
    "            best = current.copy()\n",
    "            best_energy = current_energy\n",
    "    \n",
    "    return best, best_energy\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main MTS Algorithm\n",
    "# ============================================================================\n",
    "\n",
    "def random_sequence(N: int) -> np.ndarray:\n",
    "    \"\"\"Generate a random binary sequence of +1/-1.\"\"\"\n",
    "    return np.random.choice([-1, 1], size=N)\n",
    "\n",
    "\n",
    "def mts(N: int, \n",
    "        population_size: int = 20, \n",
    "        max_generations: int = 100,\n",
    "        p_mut: float = 0.05,\n",
    "        tabu_iter: int = 100,\n",
    "        tabu_tenure: int = 7,\n",
    "        initial_population: List[np.ndarray] = None,\n",
    "        verbose: bool = True) -> Tuple[np.ndarray, int, List[np.ndarray], List[int]]:\n",
    "    \"\"\"\n",
    "    Memetic Tabu Search for the LABS problem.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Initialize population (random or provided)\n",
    "    2. Find best solution in population\n",
    "    3. For each generation:\n",
    "       a. Select two parents from population\n",
    "       b. Combine parents to create child\n",
    "       c. Mutate child with probability p_mut\n",
    "       d. Apply Tabu Search to child\n",
    "       e. If result improves best, update and replace a random population member\n",
    "    \n",
    "    Args:\n",
    "        N: Sequence length\n",
    "        population_size: Number of sequences in population\n",
    "        max_generations: Maximum number of generations\n",
    "        p_mut: Mutation probability\n",
    "        tabu_iter: Max iterations for tabu search\n",
    "        tabu_tenure: Tabu tenure length\n",
    "        initial_population: Optional initial population (for quantum seeding)\n",
    "        verbose: Print progress\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (best_sequence, best_energy, final_population, energy_history)\n",
    "    \"\"\"\n",
    "    # Initialize population\n",
    "    if initial_population is not None:\n",
    "        population = [seq.copy() for seq in initial_population[:population_size]]\n",
    "        # Fill remaining if needed\n",
    "        while len(population) < population_size:\n",
    "            population.append(random_sequence(N))\n",
    "    else:\n",
    "        population = [random_sequence(N) for _ in range(population_size)]\n",
    "    \n",
    "    # Compute initial energies\n",
    "    energies = [compute_energy(s) for s in population]\n",
    "    \n",
    "    # Find initial best\n",
    "    best_idx = np.argmin(energies)\n",
    "    best = population[best_idx].copy()\n",
    "    best_energy = energies[best_idx]\n",
    "    \n",
    "    energy_history = [best_energy]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Initial best energy: {best_energy}\")\n",
    "    \n",
    "    # Main loop\n",
    "    for gen in range(max_generations):\n",
    "        # Select two parents (tournament selection)\n",
    "        idx1, idx2 = np.random.choice(population_size, 2, replace=False)\n",
    "        p1, p2 = population[idx1], population[idx2]\n",
    "        \n",
    "        # Combine\n",
    "        child = combine(p1, p2)\n",
    "        \n",
    "        # Mutate\n",
    "        child = mutate(child, p_mut)\n",
    "        \n",
    "        # Tabu Search\n",
    "        child, child_energy = tabu_search(child, max_iter=tabu_iter, tabu_tenure=tabu_tenure)\n",
    "        \n",
    "        # Update population if child is better than worst\n",
    "        worst_idx = np.argmax(energies)\n",
    "        if child_energy < energies[worst_idx]:\n",
    "            population[worst_idx] = child\n",
    "            energies[worst_idx] = child_energy\n",
    "        \n",
    "        # Update global best\n",
    "        if child_energy < best_energy:\n",
    "            best = child.copy()\n",
    "            best_energy = child_energy\n",
    "            if verbose:\n",
    "                print(f\"Gen {gen+1}: New best energy = {best_energy}\")\n",
    "        \n",
    "        energy_history.append(best_energy)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFinal best energy: {best_energy}\")\n",
    "        print(f\"Best sequence: {best}\")\n",
    "    \n",
    "    return best, best_energy, population, energy_history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization Functions\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_results(population: List[np.ndarray], \n",
    "                      energy_history: List[int],\n",
    "                      best_sequence: np.ndarray,\n",
    "                      best_energy: int,\n",
    "                      title: str = \"MTS Results\") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Visualize MTS results including energy distribution and convergence.\n",
    "    \n",
    "    Args:\n",
    "        population: Final population\n",
    "        energy_history: Best energy at each generation\n",
    "        best_sequence: Best sequence found\n",
    "        best_energy: Best energy found\n",
    "        title: Plot title\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure object\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 1. Energy convergence over generations\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(energy_history, 'b-', linewidth=2)\n",
    "    ax1.set_xlabel('Generation', fontsize=12)\n",
    "    ax1.set_ylabel('Best Energy', fontsize=12)\n",
    "    ax1.set_title('Energy Convergence', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Final population energy distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    final_energies = [compute_energy(s) for s in population]\n",
    "    ax2.hist(final_energies, bins=20, color='green', alpha=0.7, edgecolor='black')\n",
    "    ax2.axvline(x=best_energy, color='red', linestyle='--', linewidth=2, label=f'Best: {best_energy}')\n",
    "    ax2.set_xlabel('Energy', fontsize=12)\n",
    "    ax2.set_ylabel('Count', fontsize=12)\n",
    "    ax2.set_title('Final Population Energy Distribution', fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Best sequence visualization\n",
    "    ax3 = axes[1, 0]\n",
    "    N = len(best_sequence)\n",
    "    colors = ['blue' if s == 1 else 'red' for s in best_sequence]\n",
    "    ax3.bar(range(N), best_sequence, color=colors, edgecolor='black')\n",
    "    ax3.set_xlabel('Position', fontsize=12)\n",
    "    ax3.set_ylabel('Value (+1/-1)', fontsize=12)\n",
    "    ax3.set_title(f'Best Sequence (Energy={best_energy})', fontsize=14)\n",
    "    ax3.set_ylim(-1.5, 1.5)\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # 4. Autocorrelation of best sequence\n",
    "    ax4 = axes[1, 1]\n",
    "    Ck_values = [compute_Ck(best_sequence, k) for k in range(1, N)]\n",
    "    ax4.bar(range(1, N), Ck_values, color='purple', alpha=0.7, edgecolor='black')\n",
    "    ax4.set_xlabel('Lag k', fontsize=12)\n",
    "    ax4.set_ylabel('C_k', fontsize=12)\n",
    "    ax4.set_title('Autocorrelation Coefficients', fontsize=14)\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def sequence_to_string(s: np.ndarray) -> str:\n",
    "    \"\"\"Convert +1/-1 sequence to '+'/'-' string.\"\"\"\n",
    "    return ''.join(['+' if x == 1 else '-' for x in s])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example Usage\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run MTS on a small example\n",
    "    N = 20\n",
    "    print(f\"Running MTS for LABS with N={N}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    best_seq, best_e, final_pop, history = mts(\n",
    "        N=N,\n",
    "        population_size=20,\n",
    "        max_generations=50,\n",
    "        p_mut=0.05,\n",
    "        tabu_iter=100,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBest sequence as string: {sequence_to_string(best_seq)}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig = visualize_results(final_pop, history, best_seq, best_e, f\"MTS Results for N={N}\")\n",
    "    plt.savefig('mts_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138efd4-3f55-41ab-a416-c70ea520915c",
   "metadata": {},
   "source": [
    "### Optional: GPU-Accelerated Brute-Force Validation (CuPy)\n",
    "\n",
    "To validate our heuristic results beyond CPU-feasible brute force, we implemented an **optional\n",
    "GPU-accelerated exhaustive search** using CuPy.\n",
    "\n",
    "This approach enumerates all \\(2^N\\) binary sequences in GPU batches, computes the LABS energy\n",
    "fully vectorized across the batch, and tracks the global minimum energy.\n",
    "\n",
    "This implementation is intended **strictly as a ground-truth oracle** for moderate values of \\(N\\)\n",
    "when GPU resources allow. For larger \\(N\\), exhaustive search becomes computationally prohibitive,\n",
    "and we rely on heuristic optimization methods (MTS and quantum-seeded MTS).\n",
    "\n",
    "We use this brute-force solution to:\n",
    "- Verify correctness of the `compute_energy` implementation\n",
    "- Validate convergence of the classical MTS baseline\n",
    "- Provide a trusted reference point for later quantum-enhanced methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ed7b3-d56f-4968-a0dc-840e1b2f6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# ==========================================\n",
    "# 1. 核心能量計算 (GPU Vectorized)\n",
    "# ==========================================\n",
    "def calculate_batch_energy(gpu_sequences_matrix):\n",
    "    \"\"\"\n",
    "    輸入: shape (Batch_Size, N) 的 GPU 矩陣 (值為 +1/-1)\n",
    "    輸出: shape (Batch_Size,) 的能量陣列\n",
    "    \"\"\"\n",
    "    batch_size, N = gpu_sequences_matrix.shape\n",
    "    energies = cp.zeros(batch_size, dtype=cp.float32)\n",
    "    \n",
    "    # 利用矩陣切片並行計算所有 k 的自相關\n",
    "    # 這是 LABS 能量公式 E = sum(Ck^2) 的向量化實作\n",
    "    for k in range(1, N):\n",
    "        # 這裡不使用迴圈，而是矩陣位移相乘\n",
    "        # term = s[i] * s[i+k]\n",
    "        term = gpu_sequences_matrix[:, :N-k] * gpu_sequences_matrix[:, k:]\n",
    "        \n",
    "        # 對每一列求和得到 Ck，然後平方\n",
    "        Ck = cp.sum(term, axis=1)\n",
    "        energies += Ck**2\n",
    "        \n",
    "    return energies\n",
    "\n",
    "# ==========================================\n",
    "# 2. GPU 窮舉搜尋主程式\n",
    "# ==========================================\n",
    "def solve_exact_labs_gpu(N, batch_size=10_000_000):\n",
    "    total_combinations = 1 << N\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] Starting GPU Exhaustive Search for N={N}...\")\n",
    "    print(f\"   Total combinations: {total_combinations:,}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    global_min_energy = float('inf')\n",
    "    global_best_sequences = [] \n",
    "    \n",
    "    for start_idx in range(0, total_combinations, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_combinations)\n",
    "        \n",
    "        # 1. 生成序號 (uint64)\n",
    "        indices = cp.arange(start_idx, end_idx, dtype=cp.uint64)\n",
    "        \n",
    "        # 2. [修正點] 產生位移量: 先產生 0~N-1，再反轉變成 N-1~0\n",
    "        # 這樣就避開了負數參數的問題\n",
    "        shift_amounts = cp.arange(N, dtype=cp.uint64)[::-1]\n",
    "        \n",
    "        # 進行廣播位移 (indices shape: (Batch, 1), shift shape: (N,))\n",
    "        # 結果 bits shape: (Batch, N)\n",
    "        bits = (indices[:, None] >> shift_amounts) & 1\n",
    "        \n",
    "        # 3. 轉換為 +1/-1\n",
    "        sequences = cp.where(bits == 0, 1, -1).astype(cp.int8)\n",
    "        \n",
    "        # 4. 計算能量\n",
    "        energies = calculate_batch_energy(sequences)\n",
    "        \n",
    "        # 5. 找出最小值\n",
    "        batch_min = float(cp.min(energies))\n",
    "        \n",
    "        if batch_min < global_min_energy:\n",
    "            global_min_energy = batch_min\n",
    "            min_mask = (energies == batch_min)\n",
    "            best_seqs_gpu = sequences[min_mask]\n",
    "            # 轉換回 CPU list 儲存\n",
    "            global_best_sequences = [row for row in cp.asnumpy(best_seqs_gpu)]\n",
    "            print(f\"   > New min found: {global_min_energy} (at index {start_idx})\")\n",
    "            \n",
    "        elif batch_min == global_min_energy:\n",
    "            min_mask = (energies == batch_min)\n",
    "            best_seqs_gpu = sequences[min_mask]\n",
    "            new_best = cp.asnumpy(best_seqs_gpu)\n",
    "            for seq in new_best:\n",
    "                # 簡單去重 (如果需要)\n",
    "                global_best_sequences.append(seq)\n",
    "\n",
    "        # 釋放記憶體\n",
    "        del sequences, energies, bits, indices, shift_amounts\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"EXACT SOLUTION FOUND (N={N})\")\n",
    "    print(f\"Minimum Energy: {global_min_energy}\")\n",
    "    print(f\"Time Elapsed: {elapsed:.4f} seconds\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return global_min_energy\n",
    "# ==========================================\n",
    "# 執行\n",
    "# ==========================================\n",
    "if _name_ == \"_main_\":\n",
    "    # 確保使用 GPU\n",
    "    try:\n",
    "        import cupy\n",
    "        print(f\"Using GPU: {cupy.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
    "        \n",
    "        # 執行 N=20 (約 100萬種組合，瞬間完成)\n",
    "        # solve_exact_labs_gpu(20)\n",
    "        \n",
    "        # 挑戰 N=25 (約 3300萬種組合)\n",
    "        solve_exact_labs_gpu(25)\n",
    "        \n",
    "        # 挑戰 N=30 (約 10億種組合，B系列 GPU 應該能在幾秒到幾分鐘內跑完)\n",
    "        # solve_exact_labs_gpu(30)\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Error: CuPy not installed. Please install cupy-cuda12x to run this on GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2352b-7836-4af5-a7d3-5050a83775f7",
   "metadata": {},
   "source": [
    "## Building a Quantum Enhanced Workflow\n",
    "\n",
    "Despite the effectiveness of MTS, it still exhibits exponential scaling  $O(1.34^N)$ behavior and becomes intractable for large $N$.  Quantum computing provides a potential alternative method for solving the LABS problem because the properties of entanglement, interference, and superpositon may allow for a better global search.  Recent demonstrations have even produced evidence that the quantum approximate optimization algorithm (QAOA) can be used to reduce the scaling of the LABS problem to $O(1.21^N)$ for $N$ between 28 and 40 with quantum minimum finding.\n",
    "\n",
    "However, current quantum hardware limitations restrict solution to problems of greater than about $N=20$, meaning that it will be some time before quantum approaches can outperform the classical state of the art. It should also be noted that standard QAOA can struggle with LABS and require many layers to converge the parameters if other tricks are not employed.\n",
    "\n",
    "The authors of [Scaling advantage with quantum-enhanced memetic tabu search for LABS](https://arxiv.org/html/2511.04553v1) cleverly explored an alternate path that combines quantum and classical approaches and might be able to provide a more near-term benefit.  Instead of expecting the quantum computer to solve the problem entirely, they asked how a quantum approach might enhance MTS.\n",
    "\n",
    "The basic idea is that a quantum optimization routine could run first and the resulting state be sampled to produce a better population for MTS. Many such heuristics for defining the initial population are possible, but the rest of this notebook will explore their methodology, help you to build the workflow yourself, and allow you to analyze the benefits of their approach.\n",
    "\n",
    "The first step of quantum enhanced MTS (QE-MTS) is to prepare a circuit with CUDA-Q that approximates the ground state of the Hamiltonian corresponding to the LABS problem. You could do this with any optimization algorithm such as QAOA or using an adiabatic approach.  (See the [Quantum Portfolio Optimization](https://github.com/NVIDIA/cuda-q-academic/blob/main/quantum-applications-to-finance/03_qchop.ipynb) CUDA-Q Academic lab for a detailed comparison of these two common approaches.)\n",
    "\n",
    "The authors of this work opted for an adiabatic approach (More on why later). Recall that the goal of an adiabatic optimization is to begin with a Hamiltonian that has an easily prepared ground state ($H_i$). Then, the adiabatic Hamiltonian $H_{ad}$ can be constructed as $H_{ad}(\\lambda) = (1-\\lambda)H_i +\\lambda H_f $, where $\\lambda$ is a function of time and $H_f$ is the Hamiltonian representing a qubit encoding of the LABS problem. \n",
    "\n",
    "$$H_f = 2 \\sum_{i=1}^{N-2} \\sigma_i^z \\sum_{k=1}^{\\lfloor \\frac{N-i}{2} \\rfloor} \\sigma_{i+k}^z \n",
    "+ 4 \\sum_{i=1}^{N-3} \\sigma_i^z \\sum_{t=1}^{\\lfloor \\frac{N-i-1}{2} \\rfloor} \\sum_{k=t+1}^{N-i-t} \\sigma_{i+t}^z \\sigma_{i+k}^z \\sigma_{i+k+t}^z$$\n",
    "\n",
    "The authors also selected $H_i = \\sum_i h^x_i \\sigma^x_i $ which has an easily prepared ground state of $\\ket{+}^{\\otimes N}$.\n",
    "\n",
    "The challenge for implementing the optimization procedure becomes selection of an operator that will quickly and accurately evolve to the ground state of $H_f$.  One approach is to use a so-called auxiliary countradiabatic (CD) term $H_{CD}$, which corrects diabatic transitions that jump out of the ground state during the evolution. The figure below demonstrates the benefit of using a CD correction.\n",
    "\n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/counteradiabatic.png\" width=\"900\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "An operator called the adiabatic gauge potential $A_{\\lambda}$ is the ideal choice for the CD term as it suppresses all possible diabatic transitions, resulting in the following total system to evolve.\n",
    "\n",
    "$$ H(\\lambda) = H_{ad}(\\lambda) + \\lambda H_{CD} (\\lambda) $$\n",
    "\n",
    "$A(\\lambda)$ is derrived from $H_{ad}(\\lambda)$  (see paper for details) as it contains information about underlying physics of the problem. \n",
    "\n",
    "There is a problem though.  The $A(\\lambda)$ term cannot be efficiently expressed exactly and needs to be approximated.  It also turns out that in the so called impulse regime, where the adiabatic evolution is very fast, $H_{cd} (\\lambda)$ dominates $H_{ad}(\\lambda)$, meaning that the final implementation corresponds to the operator $H(\\lambda) = H^1_{cd}(\\lambda)$ where  $H^1_{cd}(\\lambda)$ is a first order approximation of $A(\\lambda)$ (see equation 7 in the paper).\n",
    "\n",
    "A final step is to use Trotterization to define the quantum circuit to apply $e^{-\\theta (t) i H_{cd}}$. The details for this derivation are shown in the appendix of the paper. and result from equation B3 is shown below.  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "U(0, T) = \\prod_{n=1}^{n_{\\text{trot}}} & \\left[ \\prod_{i=1}^{N-2} \\prod_{k=1}^{\\lfloor \\frac{N-i}{2} \\rfloor} R_{Y_i Z_{i+k}}\\big(4\\theta(n\\Delta t)h_i^x\\big) R_{Z_i Y_{i+k}}\\big(4\\theta(n\\Delta t)h_{i+k}^x\\big) \\right] \\\\\n",
    "& \\times \\prod_{i=1}^{N-3} \\prod_{t=1}^{\\lfloor \\frac{N-i-1}{2} \\rfloor} \\prod_{k=t+1}^{N-i-t} \\bigg( R_{Y_i Z_{i+t} Z_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_i^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Y_{i+t} Z_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+t}^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Z_{i+t} Y_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+k}^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Z_{i+t} Z_{i+k} Y_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+k+t}^x\\big) \\bigg)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "It turns out that this implementation is more efficient than QAOA in terms of gate count. The authors calculated that for $N=67$, QAOA would require 1.4 million entangling gates while the CD approach derived here requires only 236 thousand entangling gates.\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 3:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "At first glance, this equation might looks quite complicated. However, observe the structure and note two \"blocks\" of terms.  Can you spot them?  \n",
    "\n",
    "They are 2 qubit terms that look like $R_{YZ}(\\theta)$ or $R_{ZY}(\\theta)$.\n",
    "\n",
    "As well as 4 qubit terms that look like $R_{YZZZ}(\\theta)$, $R_{ZYZZ}(\\theta)$, $R_{ZZYZ}(\\theta)$, or $R_{ZZZY}(\\theta)$.\n",
    "\n",
    "Thankfully the authors derive a pair of circuit implementations for the two and four qubit terms respectively, shown in the figures below.\n",
    "\n",
    "Using CUDA-Q, write a kernel for each which will be used later to construct the full implementation.\n",
    "\n",
    "* Hint: Remember that the adjoint of a rotation gate is the same as rotating in the opposite direction. \n",
    "\n",
    "* Hint: You may also want to define a CUDA-Q kernel for an R$_{ZZ}$ gate.\n",
    "\n",
    "* Hint: Implementing a circuit from a paper is a great place where AI can help accelerate your work.  If you have access to a coding assistant, feel free to use it here.\n",
    "</div>\n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/kernels.png\" width=\"1300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e200d1-c536-4a3e-91ca-d660ae304a43",
   "metadata": {},
   "source": [
    "## Exercise 3: CUDA-Q Kernels for 2-Qubit and 4-Qubit Operators\n",
    "\n",
    "### Goal\n",
    "\n",
    "The LABS Hamiltonian contains interaction terms that map to **2-qubit** and **4-qubit Pauli products**.\n",
    "To enable quantum evaluation (and later quantum-seeded / hybrid optimization), we implemented\n",
    "**CUDA-Q kernels** that realize these operators as reusable circuit blocks.\n",
    "\n",
    "---\n",
    "\n",
    "### What we implemented\n",
    "\n",
    "We defined three modular CUDA-Q kernels:\n",
    "\n",
    "- **`rzz(q0, q1, θ)`**  \n",
    "  A helper implementing the two-qubit interaction\n",
    "\n",
    "  `R_ZZ(θ) = exp(-i * θ / 2 * Z ⊗ Z)`\n",
    "\n",
    "  using the standard gate decomposition:\n",
    "\n",
    "  `CNOT(q0, q1) → Rz(q1, θ) → CNOT(q0, q1)`.\n",
    "\n",
    "- **`two_qubit_block(q0, q1, θ)`**  \n",
    "  A 2-qubit building block that composes basis transformations with `RZZ` gates to realize the\n",
    "  operator structure shown in the paper’s Fig. 3. This effectively implements coupled two-body\n",
    "  interactions using single-qubit rotations and entangling gates.\n",
    "\n",
    "- **`four_qubit_block(q0, q1, q2, q3, θ)`**  \n",
    "  A 4-qubit building block following the paper’s Fig. 4 decomposition to realize higher-order\n",
    "  interaction structure (Pauli-string-style terms across four qubits).\n",
    "\n",
    "  We implemented this kernel using **explicit qubit arguments** (rather than passing a `qvector`)\n",
    "  to match CUDA-Q kernel signature constraints and to keep kernel calls explicit and readable.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this design\n",
    "\n",
    "We intentionally kept the kernels **modular** (`RZZ → 2-qubit block → 4-qubit block`) so that we can:\n",
    "\n",
    "- Reuse the same primitives across different LABS sizes and Hamiltonian term groupings\n",
    "- Integrate these blocks into a larger **hybrid classical–quantum workflow** without rewriting circuits\n",
    "- Swap decompositions or introduce approximations later if needed\n",
    "\n",
    "This design keeps the quantum component flexible and extensible within the overall optimization pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Verification\n",
    "\n",
    "To sanity-check correctness at the **circuit-structure level**, we used `cudaq.draw` to render both blocks:\n",
    "\n",
    "- **`test_draw_g2(θ)`** renders the 2-qubit architecture (Fig. 3)\n",
    "- **`test_draw_g4(θ)`** renders the 4-qubit architecture (Fig. 4)\n",
    "\n",
    "This confirms that our implementation matches the intended **gate ordering and entanglement pattern**\n",
    "before integrating these kernels into energy evaluation or quantum-seed generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bbaae-62a1-41e7-a285-af885627a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO  Write CUDA-Q kernels to apply the 2 and 4 qubit operators. \n",
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# RZZ Gate Helper\n",
    "# ============================================================================\n",
    "@cudaq.kernel\n",
    "def rzz(q0: cudaq.qubit, q1: cudaq.qubit, theta: float):\n",
    "    \"\"\"\n",
    "    Implements R_ZZ(θ) = exp(-i * θ/2 * Z ⊗ Z).\n",
    "    Structure: CNOT(q0, q1) -> Rz(q1, θ) -> CNOT(q0, q1).\n",
    "    \"\"\"\n",
    "    x.ctrl(q0, q1)\n",
    "    rz(theta, q1)\n",
    "    x.ctrl(q0, q1)\n",
    "\n",
    "# ============================================================================\n",
    "# FIG 3: Two-Qubit Block Implementation\n",
    "# ============================================================================\n",
    "@cudaq.kernel\n",
    "def two_qubit_block(q0: cudaq.qubit, q1: cudaq.qubit, theta: float):\n",
    "    \"\"\"\n",
    "    Implements the decomposition of R_YZ(θ)R_ZY(θ).\n",
    "    Requires 2 Rzz gates and 4 single-qubit rotation gates.\n",
    "    \"\"\"\n",
    "    # First rotation: Ryz basis transformation\n",
    "    rx(np.pi/2, q0)\n",
    "    rzz(q0, q1, theta)\n",
    "    rx(-np.pi/2, q0)\n",
    "\n",
    "    # Second rotation: Rzy basis transformation\n",
    "    rx(np.pi/2, q1)\n",
    "    rzz(q0, q1, theta)\n",
    "    rx(-np.pi/2, q1)\n",
    "\n",
    "# ============================================================================\n",
    "# FIG 4: Four-Qubit Block Implementation (Fixed for qvector input)\n",
    "# ============================================================================\n",
    "@cudaq.kernel\n",
    "def four_qubit_block(q0: cudaq.qubit, q1: cudaq.qubit, q2: cudaq.qubit, q3: cudaq.qubit, theta: float):\n",
    "    \"\"\"\n",
    "    Implements the decomposition of R_YZZZ, R_ZYZZ, R_ZZYZ, R_ZZZY.\n",
    "    This version uses individual qubit objects as arguments to match \n",
    "    the caller's signature requirements.\n",
    "    \"\"\"\n",
    "    # --- Phase 1: Initial Transformation Layer --- \n",
    "    rx(-np.pi/2, q0)\n",
    "    ry(np.pi/2, q1)\n",
    "    ry(-np.pi/2, q2)\n",
    "\n",
    "    # --- Phase 2: First Entanglement Sequence ---\n",
    "    rzz(q0, q1, -np.pi/2)\n",
    "    rzz(q2, q3, -np.pi/2)\n",
    "\n",
    "    rx(np.pi/2, q0)\n",
    "    ry(-np.pi/2, q1)\n",
    "    ry(np.pi/2, q2)\n",
    "    rx(-np.pi/2, q3)\n",
    "\n",
    "    # --- Phase 3: Secondary Entanglement (Theta Injection) ---\n",
    "    rx(-np.pi/2, q1)\n",
    "    rx(-np.pi/2, q2)\n",
    "\n",
    "    rzz(q1, q2, theta)\n",
    "    \n",
    "    rx(np.pi/2, q1)\n",
    "    rx(np.pi, q2)\n",
    "\n",
    "    # --- Phase 4: Long-range Entanglement ---\n",
    "    ry(np.pi/2, q1)\n",
    "    rzz(q0, q1, np.pi/2)\n",
    "    rx(np.pi/2, q0)\n",
    "    ry(-np.pi/2, q1)\n",
    "\n",
    "    # --- Phase 5: Central Symmetry Layer ---\n",
    "    # Strictly following the gate sequence with individual qubit variables\n",
    "    rzz(q1, q2, -theta) \n",
    "    rx(np.pi/2, q1)\n",
    "    rx(-np.pi, q2)\n",
    "\n",
    "    rzz(q1, q2, -theta)\n",
    "    rx(-np.pi, q1)\n",
    "    ry(np.pi/2, q2)\n",
    "\n",
    "    # --- Phase 6: Third Entanglement Sequence ---\n",
    "    rzz(q2, q3, -np.pi/2)\n",
    "    rx(-np.pi/2, q3)\n",
    "    ry(-np.pi/2, q2)\n",
    "    rx(-np.pi, q2)\n",
    "\n",
    "    # --- Phase 7: Penultimate Entanglement Sequence ---\n",
    "    rzz(q1, q2, theta)\n",
    "    rx(np.pi/2, q1)\n",
    "    rx(np.pi/2, q2)\n",
    "    ry(-np.pi/2, q1) \n",
    "    ry(np.pi/2, q2)\n",
    "\n",
    "    # --- Phase 8: Final Closing Layer ---\n",
    "    rzz(q0, q1, np.pi/2)\n",
    "    rzz(q2, q3, np.pi/2)\n",
    "    ry(np.pi/2, q1)\n",
    "    ry(-np.pi/2, q2)\n",
    "    rx(np.pi/2, q3)\n",
    "\n",
    "print(\"Quantum kernels for LABS defined successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Verification and Drawing\n",
    "# ============================================================================\n",
    "\n",
    "@cudaq.kernel\n",
    "def test_draw_g2(theta: float):\n",
    "    q = cudaq.qvector(2)\n",
    "    two_qubit_block(q[0], q[1], theta)\n",
    "\n",
    "print(\"--- FIG 3: Two-Qubit Block Architecture ---\")\n",
    "print(cudaq.draw(test_draw_g2, 0.5))\n",
    "\n",
    "@cudaq.kernel\n",
    "def test_draw_g4(theta: float):\n",
    "    q = cudaq.qvector(4)\n",
    "    four_qubit_block(q[0], q[1],q[2], q[3], theta) # Correctly passing the qvector\n",
    "\n",
    "print(\"\\n--- FIG 4: Four-Qubit Block Architecture ---\")\n",
    "print(cudaq.draw(test_draw_g4, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113f324-6f58-4b5e-ab93-339d70f88c46",
   "metadata": {},
   "source": [
    "There are a few additional items we need to consider before completing the final implementation of the entire circuit.  One simplification we can make is that for our problem the $h_i^x$ terms are all 1 and any $h_b^x$ terms are 0, and are only there for generalizations of this model. \n",
    "\n",
    "The remaining challenge is derivation of the angles that are used to apply each of the circuits you defined above. These are obtained from two terms $\\lambda(t)$ and $\\alpha(t)$.  \n",
    "\n",
    "\n",
    "The $\\lambda(t)$ defines an annealing schedule and is generally a Sin function which slowly \"turns on\" the problem Hamiltonian.  For computing our angles, we need the derivative of $\\lambda(t)$.\n",
    "\n",
    "The $\\alpha$ term is a bit trickier and is the solution to a set of differential equations which minimize the distance between $H^1_{CD}(\\lambda)$ and $A(\\lambda)$.  The result is \n",
    "\n",
    "$$\\alpha(t) = \\frac{-\\Gamma_1(t)}{\\Gamma_2(t)} $$\n",
    "\n",
    "Where $\\Gamma_1(t)$ and $\\Gamma_2(t)$ are defined in equations 16 and 17 of the paper and essentially depend on the structure of the optimization problem.  Curious learners can look at the functions in `labs_utils.py`  to see how these are computed, based on the problem size and specific time step in the Trotter process. \n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 4:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "The `compute_theta` function, called in the following cells, requires all indices of the two and four body terms. These will be used again in our main kernel to apply the respective gates.  Use the products in the formula below to finish the function in the cell below.  Save them as `G2` and `G4` where each is a list of lists of indices defining the two and four term interactions. As you are translating an equation to a set of loops, this is a great opportunity to use an AI coding assistant.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "U(0, T) = \\prod_{n=1}^{n_{\\text{trot}}} & \\left[ \\prod_{i=1}^{N-2} \\prod_{k=1}^{\\lfloor \\frac{N-i}{2} \\rfloor} R_{Y_i Z_{i+k}}\\big(4\\theta(n\\Delta t)h_i^x\\big) R_{Z_i Y_{i+k}}\\big(4\\theta(n\\Delta t)h_{i+k}^x\\big) \\right] \\\\\n",
    "& \\times \\prod_{i=1}^{N-3} \\prod_{t=1}^{\\lfloor \\frac{N-i-1}{2} \\rfloor} \\prod_{k=t+1}^{N-i-t} \\bigg( R_{Y_i Z_{i+t} Z_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_i^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Y_{i+t} Z_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+t}^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Z_{i+t} Y_{i+k} Z_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+k}^x\\big) \\\\\n",
    "& \\quad \\times R_{Z_i Z_{i+t} Z_{i+k} Y_{i+k+t}}\\big(8\\theta(n\\Delta t)h_{i+k+t}^x\\big) \\bigg)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620a605-d89b-4336-a411-9ec2f24de079",
   "metadata": {},
   "source": [
    "## Exercise 4: Enumerating 2-Body and 4-Body LABS Interactions\n",
    "\n",
    "### Goal\n",
    "\n",
    "After defining the quantum circuit primitives, the next step is to determine **which qubits interact**\n",
    "for a given LABS instance of length `N`.\n",
    "\n",
    "The LABS Hamiltonian can be expressed as a sum of:\n",
    "- **2-body interaction terms** (G2)\n",
    "- **4-body interaction terms** (G4)\n",
    "\n",
    "In this exercise, we programmatically generate all valid index combinations for these interaction\n",
    "terms and verify that their counts match the theoretical expressions.\n",
    "\n",
    "---\n",
    "\n",
    "### What we implemented\n",
    "\n",
    "We implemented a function `get_interactions(N)` that enumerates:\n",
    "\n",
    "- **G2 interactions**  \n",
    "  Pairs of indices `[i, i+k]` corresponding to valid 2-body interaction terms derived from the LABS autocorrelation structure.\n",
    "\n",
    "- **G4 interactions**  \n",
    "  Quadruples of indices `[i, i+t, i+k, i+k+t]` corresponding to valid 4-body interaction terms arising from squared autocorrelation contributions.\n",
    "\n",
    "All indices are converted to **0-based indexing** so they can be used directly in Python and CUDA-Q kernels.\n",
    "\n",
    "---\n",
    "\n",
    "### Theoretical validation\n",
    "\n",
    "To ensure correctness, we independently computed the **theoretical counts** of G2 and G4 terms as functions of `N`:\n",
    "\n",
    "- G2 count:  \n",
    "  Sum over `i = 1` to `N-2` of `floor((N - i) / 2)`\n",
    "\n",
    "- G4 count:  \n",
    "  Sum over valid `(i, t, k)` ranges derived from the LABS autocorrelation expansion\n",
    "\n",
    "We implemented `get_theoretical_counts(N)` to compute these values analytically.\n",
    "\n",
    "---\n",
    "\n",
    "### Automated verification\n",
    "\n",
    "We then performed an automated verification across a range of problem sizes using\n",
    "`automated_verify(N_range)`.\n",
    "\n",
    "For each `N`, we compare:\n",
    "- The number of generated G2 interactions vs. the theoretical G2 count\n",
    "- The number of generated G4 interactions vs. the theoretical G4 count\n",
    "\n",
    "A test passes only if **both counts match exactly**.\n",
    "\n",
    "This verification confirms that our interaction enumeration is:\n",
    "- Complete (no missing terms)\n",
    "- Non-redundant (no overcounting)\n",
    "- Consistent with the theoretical LABS Hamiltonian structure\n",
    "\n",
    "---\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "Correct interaction indexing is critical before constructing the quantum Hamiltonian.\n",
    "Any missing or duplicated interaction would lead to an incorrect energy landscape and\n",
    "invalidate both classical and quantum optimization results.\n",
    "\n",
    "This step ensures that subsequent quantum kernels are applied to the **correct interaction structure**\n",
    "for arbitrary sequence lengths `N`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf34168-42f9-4dbf-86e1-99976232ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_interactions(N):\n",
    "    G2 = []\n",
    "    G4 = []\n",
    "    \n",
    "    # G2 indices: i from 1 to N-2\n",
    "    for i in range(1, N - 1): \n",
    "        # k from 1 to floor((N-i)/2)\n",
    "        for k in range(1, (N - i) // 2 + 1):\n",
    "            # 轉換為 0 索引：(i-1) 和 (i+k-1)\n",
    "            G2.append([i - 1, i + k - 1])\n",
    "\n",
    "    # G4 indices: i from 1 to N-3\n",
    "    for i in range(1, N - 2):\n",
    "        # t from 1 to floor((N-i-1)/2)\n",
    "        for t in range(1, (N - i - 1) // 2 + 1):\n",
    "            # k from t+1 to N-i-t\n",
    "            for k in range(t + 1, N - i - t + 1):\n",
    "                # 轉換為 0 索引\n",
    "                G4.append([i - 1, i + t - 1, i + k - 1, i + k + t - 1])\n",
    "                \n",
    "    return G2, G4\n",
    "\n",
    "def get_theoretical_counts(N):\n",
    "    # G2 理論值：Sum_{i=1}^{N-2} floor((N-i)/2)\n",
    "    theo_g2 = sum(math.floor((N - i) / 2) for i in range(1, N - 1))\n",
    "    \n",
    "    # G4 理論值：計算 k 的區間長度 (N-i-t) - (t+1) + 1 = N-i-2t\n",
    "    theo_g4 = 0\n",
    "    for i in range(1, N - 2):\n",
    "        for t in range(1, math.floor((N - i - 1) / 2) + 1):\n",
    "            theo_g4 += (N - i - 2 * t)\n",
    "            \n",
    "    return theo_g2, theo_g4\n",
    "\n",
    "def automated_verify(N_range):\n",
    "    print(f\"{'N':<5} | {'G2 Status':<12} | {'G4 Status':<12} | {'Result'}\")\n",
    "    print(\"-\" * 50)\n",
    "    for n in N_range:\n",
    "        g2, g4 = get_interactions(n)\n",
    "        t2, t4 = get_theoretical_counts(n)\n",
    "        \n",
    "        match = (len(g2) == t2) and (len(g4) == t4)\n",
    "        status = \"✅ PASS\" if match else \"❌ FAIL\"\n",
    "        print(f\"{n:<5} | {len(g2):>3}/{t2:<3}      | {len(g4):>3}/{t4:<3}      | {status}\")\n",
    "\n",
    "# 執行驗證\n",
    "automated_verify(range(5, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450f200-b191-41f5-88d2-974052ee45ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 5:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "You are now ready to construct the entire circuit and run the counteradiabatic optimization procedure. The final kernel needs to apply Equation 15 for a specified total evolution time $T$ and the `n_steps` number of Trotter steps.  It must also take as input, the indices for the two and four body terms and the thetas to be applied each step, as these cannot be computed within a CUDA-Q kernel.\n",
    "\n",
    "The helper function `compute_theta` computes the theta parameters for you, using a few additional functions in accordance with the equations defined in the paper.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67c37a-f2e7-497b-97e8-7aa173d0faa3",
   "metadata": {},
   "source": [
    "## Exercise 5: Trotterized Quantum Sampling for LABS (Quantum Seed Generation)\n",
    "\n",
    "### Goal\n",
    "\n",
    "After implementing the CUDA-Q operator blocks (Exercise 3) and enumerating the valid interaction indices (Exercise 4),\n",
    "we constructed a **trotterized quantum circuit** that applies all LABS interaction terms in a controlled sequence.\n",
    "The purpose of this circuit is to **sample candidate bitstrings** that can be used as high-quality initial solutions\n",
    "(seeds) for the classical Memetic Tabu Search (MTS).\n",
    "\n",
    "---\n",
    "\n",
    "### What we implemented\n",
    "\n",
    "We implemented a CUDA-Q kernel `trotterized_circuit(N, G2, G4, steps, thetas)` with the following structure:\n",
    "\n",
    "1. **Initialization**  \n",
    "   Allocate `N` qubits and apply a layer of Hadamards `h(reg)` to start from a uniform superposition.\n",
    "   This ensures broad coverage of the search space at the start of the evolution.\n",
    "\n",
    "2. **Trotterized evolution (steps loop)**  \n",
    "   For each trotter step, we apply:\n",
    "   - All **2-qubit interaction blocks** across pairs in `G2`\n",
    "   - All **4-qubit interaction blocks** across quartets in `G4`\n",
    "\n",
    "   Each step uses a step-specific parameter `current_theta = thetas[step]`, computed on the host before circuit execution.\n",
    "\n",
    "3. **Measurement**  \n",
    "   We measure all qubits with `mz(reg)` and collect sampled bitstrings.\n",
    "\n",
    "---\n",
    "\n",
    "### Parameter schedule (theta)\n",
    "\n",
    "The circuit uses a stepwise parameter schedule `thetas` computed on the CPU using a helper routine\n",
    "(`utils.compute_theta(...)`) based on the counteradiabatic protocol described in the reference approach.\n",
    "In our implementation, we pre-compute the full theta list before launching the kernel to keep the kernel logic minimal.\n",
    "\n",
    "---\n",
    "\n",
    "### How we use the output\n",
    "\n",
    "We run `cudaq.sample(...)` to obtain a distribution over bitstrings (and their counts).\n",
    "The highest-frequency samples are treated as **quantum-generated candidate solutions**.\n",
    "\n",
    "These samples are then used as **seeds** for the classical MTS optimizer:\n",
    "- Instead of starting MTS from purely random sequences, we start from quantum-sampled candidates\n",
    "- This improves early convergence behavior and provides a practical hybrid workflow (quantum sampling → classical refinement)\n",
    "\n",
    "---\n",
    "\n",
    "### Notes / limitations\n",
    "\n",
    "- This implementation uses a small number of trotter steps (`n_steps = 1`) for simplicity and runtime constraints.\n",
    "  Increasing the number of steps is possible, but increases circuit depth and cost.\n",
    "- The goal here is not to claim full quantum advantage, but to demonstrate a working and extensible\n",
    "  quantum-seeded hybrid optimization pipeline for LABS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e6d7d-03b2-482f-bc36-d572e6d4855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# Trotterized Circuit Kernel\n",
    "# ============================================================================\n",
    "@cudaq.kernel\n",
    "def trotterized_circuit(N: int, G2: list[list[int]], G4: list[list[int]], steps: int, thetas: list[float]):\n",
    "    reg = cudaq.qvector(N)\n",
    "    h(reg)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        current_theta = thetas[step]\n",
    "        \n",
    "        # Two-qubit interactions\n",
    "        for pair in G2:\n",
    "            two_qubit_block(reg[pair[0]], reg[pair[1]], current_theta)\n",
    "            \n",
    "        # Four-qubit interactions\n",
    "        for quartet in G4:\n",
    "            # Here you pass 4 qubits + 1 float = 5 arguments (MATCHED!)\n",
    "            four_qubit_block(\n",
    "                reg[quartet[0]], \n",
    "                reg[quartet[1]], \n",
    "                reg[quartet[2]], \n",
    "                reg[quartet[3]], \n",
    "                current_theta\n",
    "            )\n",
    "\n",
    "    mz(reg)\n",
    "\n",
    "# ============================================================================\n",
    "# Main Execution Logic\n",
    "# ============================================================================\n",
    "\n",
    "# Define Simulation Parameters\n",
    "T = 1.0               # Total evolution time\n",
    "n_steps = 1           # Number of Trotter steps defined in the exercise\n",
    "dt = T / n_steps      # Time increment per step\n",
    "N = 20                # Number of qubits\n",
    "\n",
    "# Generate interaction indices (verified in Exercise 4)\n",
    "G2, G4 = get_interactions(N)\n",
    "\n",
    "# Pre-compute theta parameters using the helper utility\n",
    "# This is done on the host (CPU) before launching the QPU kernel\n",
    "thetas = []\n",
    "for step in range(1, n_steps + 1):\n",
    "    t = step * dt\n",
    "    # Compute theta according to the paper's Counteradiabatic protocol\n",
    "    theta_val = utils.compute_theta(t, dt, T, N, G2, G4)\n",
    "    thetas.append(theta_val)\n",
    "\n",
    "# Execute the simulation using the NVIDIA GPU-accelerated backend\n",
    "# The sample function returns a dictionary of bitstrings and their counts\n",
    "print(f\"Launching simulation for N={N} with {n_steps} Trotter steps...\")\n",
    "result = cudaq.sample(trotterized_circuit, N, G2, G4, n_steps, thetas)\n",
    "\n",
    "# Output results for population initialization\n",
    "print(\"Sampling complete. Top sequences will be used for MTS seeding.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89d90e-66e2-4700-85b9-40df9fca22c1",
   "metadata": {},
   "source": [
    "## Generating Quantum Enhanced Results\n",
    "\n",
    "Recall that the point of this lab is to demonstrate the potential benefits of running a quantum subroutine as a preprocessing step for classical optimization of a challenging problem like LABS. you now have all of the tools you need to try this for yourself.\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px; box-shadow: 0px 2px 4px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0; margin-bottom: 10px;\">Exercise 6:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "Use your CUDA-Q code to prepare an initial population for your memetic search algorithm and see if you can improve the results relative to a random initial population.  If you are running on a CPU, you will need to run smaller problem instances. The code below sets up the problem\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f02e6-41bf-4634-9cb1-f0f543ef2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Quantum-seeded MTS population (fixed for Exercise 5 kernel)\n",
    "# -------------------------------------------------------------\n",
    "import inspect\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Assumes these already exist from previous cells:\n",
    "# - cudaq imported\n",
    "# - trotterized_circuit defined as trotterized_circuit(N, G2, G4, steps, thetas)\n",
    "# - N, G2, G4, n_steps, thetas defined\n",
    "# - mts, compute_energy, visualize_results, sequence_to_string imported\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Sample your CUDA-Q kernel\n",
    "# ----------------------------\n",
    "shots = 2000           # increase if you want a cleaner distribution\n",
    "population_size = 20\n",
    "\n",
    "def _cudaq_sample_kernel(shots: int):\n",
    "    \"\"\"\n",
    "    Robust sampling wrapper: tries common CUDA-Q sample argument names.\n",
    "    Returns a dict-like counts object: {bitstring: count}.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return cudaq.sample(\n",
    "            trotterized_circuit,\n",
    "            N, G2, G4, n_steps, thetas,\n",
    "            shots_count=shots\n",
    "        )\n",
    "    except TypeError:\n",
    "        # some versions use \"shots\" instead\n",
    "        return cudaq.sample(\n",
    "            trotterized_circuit,\n",
    "            N, G2, G4, n_steps, thetas,\n",
    "            shots=shots\n",
    "        )\n",
    "\n",
    "counts = _cudaq_sample_kernel(shots)\n",
    "\n",
    "# Safely extract items (bitstring, count)\n",
    "try:\n",
    "    items = list(counts.items())\n",
    "except Exception:\n",
    "    items = list(dict(counts).items())\n",
    "\n",
    "# Sort by frequency so we see the distribution clearly (optional but nice)\n",
    "items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Sampling complete: {len(items)} unique bitstrings from {shots} shots.\")\n",
    "print(\"Top 5 most frequent samples:\", items[:5])\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2) Bitstring -> ±1 numpy array (LABS format)\n",
    "# -------------------------------------------\n",
    "def bitstring_to_pm1_array(bs: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map measurement string to ±1:\n",
    "      '0' -> +1\n",
    "      '1' -> -1\n",
    "    Returns np.ndarray of shape (N,).\n",
    "    \"\"\"\n",
    "    return np.array([1 if b == \"0\" else -1 for b in bs], dtype=np.int8)\n",
    "\n",
    "# Convert unique measured strings into candidates (keep uniqueness for diversity)\n",
    "candidates = []\n",
    "for bs, ct in items:\n",
    "    if len(bs) != N:\n",
    "        # If backend includes spaces or prefix, you might need to sanitize bs.\n",
    "        # This is just a safety check.\n",
    "        continue\n",
    "    candidates.append(bitstring_to_pm1_array(bs))\n",
    "\n",
    "print(f\"Converted {len(candidates)} candidates of length N={N}.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Rank quantum candidates by classical LABS energy & seed pop\n",
    "# ------------------------------------------------------------\n",
    "# Compute energies once so we don't recompute in sorting repeatedly\n",
    "cand_energies = [(seq, compute_energy(seq)) for seq in candidates]\n",
    "cand_energies.sort(key=lambda x: x[1])  # low energy first\n",
    "\n",
    "# Take best unique sequences (diverse seeding)\n",
    "seed_pop = [seq for (seq, E) in cand_energies[:population_size]]\n",
    "\n",
    "# If not enough unique quantum samples, fill remainder randomly\n",
    "while len(seed_pop) < population_size:\n",
    "    seed_pop.append(np.array([random.choice([-1, 1]) for _ in range(N)], dtype=np.int8))\n",
    "\n",
    "print(\"Seed population size:\", len(seed_pop))\n",
    "print(\"Best few seeded energies:\", [compute_energy(s) for s in seed_pop[:5]])\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4) Run MTS: random init vs quantum init\n",
    "# ----------------------------------------\n",
    "mts_kwargs = dict(\n",
    "    N=N,\n",
    "    population_size=population_size,\n",
    "    max_generations=50,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=100,\n",
    "    tabu_tenure=7,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Baseline random\n",
    "best_seq_rand, best_E_rand, final_pop_rand, hist_rand = mts(**mts_kwargs)\n",
    "\n",
    "# Seeded run (your mts supports initial_population already)\n",
    "sig = inspect.signature(mts)\n",
    "if \"initial_population\" not in sig.parameters:\n",
    "    raise RuntimeError(\"Your mts() does not support initial_population, but your pasted version should.\")\n",
    "best_seq_seed, best_E_seed, final_pop_seed, hist_seed = mts(\n",
    "    **mts_kwargs,\n",
    "    initial_population=seed_pop\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Print + visualize results\n",
    "# ---------------------------\n",
    "print(\"\\n==================== COMPARISON ====================\")\n",
    "print(f\"Random init  best E: {best_E_rand:>4d} | best seq: {sequence_to_string(best_seq_rand)}\")\n",
    "print(f\"Quantum init best E: {best_E_seed:>4d} | best seq: {sequence_to_string(best_seq_seed)}\")\n",
    "\n",
    "fig1 = visualize_results(final_pop_rand, hist_rand, best_seq_rand, best_E_rand,\n",
    "                         f\"Random-seeded MTS (N={N})\")\n",
    "fig2 = visualize_results(final_pop_seed, hist_seed, best_seq_seed, best_E_seed,\n",
    "                         f\"Quantum-seeded MTS (N={N})\")\n",
    "\n",
    "plt.show()\n",
    "#-+-+----+----++-++--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5756e2-e4cb-42f4-a4b3-7f627095f4f4",
   "metadata": {},
   "source": [
    "The results clearly show that a population sampled from CUDA-Q results in an improved distribution and a lower energy final result. This is exactly the goal of quantum enhanced optimization.  To not necessarily solve the problem, but improve the effectiveness of state-of-the-art classical approaches. \n",
    "\n",
    "A few major caveats need to be mentioned here. First, We are comparing a quantum generated population to a random sample.  It is quite likely that other classical or quantum heuristics could be used to produce an initial population that might even beat the counteradiabatic method you used, so we cannot make any claims that this is the best. \n",
    "\n",
    "Recall that the point of the counteradiabatic approach derived in the paper is that it is more efficient in terms of two-qubit gates relative to QAOA. The benefits of this regime would only truly come into play in a setting (e.g. larger problem instance) where it is too difficult to produce a good initial population with any know classical heuristic, and the counteradiabatic approach is more efficiently run on a QPU compared to alternatives.\n",
    "\n",
    "We should also note that we are comparing a single sample of each approach.  Maybe the quantum sample got lucky or the randomly generated population was unlucky and a more rigorous comparison would need to repeat the analysis many times to draw any confidently conclusions.  \n",
    "\n",
    "The authors of the paper discuss all of these considerations, but propose an analysis that is quite interesting related to the scaling of the technique. Rather than run large simulations ourselves, examine their results below. \n",
    "\n",
    "\n",
    "<img src=\"images/quantum_enhanced_optimization_LABS/tabu_search_results.png\" width=\"900\">\n",
    "\n",
    "The authors computed replicate median (median of solving the problem repeated with same setup) time to solutions (excluding time to sample from QPU) for problem sizes $N=27$ to $N=37$. Two interesting conclusions can be drawn from this. First, standard memetic tabu search (MTS) is generally faster than quantum enhanced (QE) MTS.  But there are two promising trends. For larger problems, the QE-MTS experiments occasionally have excellent performance with times to solution much smaller than all of the MTS data points.  These outliers indicate there are certain instances where QE-MTS could provide much faster time-to-solution. \n",
    "\n",
    "More importantly, if a line of best fit is calculated using the median of each set of medians, the slope of the QE-MTS line is smaller than the MTS!  This seems to indicate that QE solution of this problem scales $O(1.24^N)$ which is better than the best known classical heuristic ($O(1.34^N)$) and the best known quantum approach (QAOA - $O(1.46^N)$).\n",
    "\n",
    "For problems of size of $N=47$ or greater, the authors anticipate that QE-MTS could be a promising technique and produce good initial populations that are difficult to obtain classically. \n",
    "\n",
    "The study reinforces the potential of hybrid workflows enhanced by quantum data such that a classical routine is still the primary solver, but quantum computers make it much more effective.  Future work can explore improvements to both the quantum and classical sides, such as including GPU accelerated memetic search on the classical side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab7af9",
   "metadata": {},
   "source": [
    "## Self-validation To Be Completed for Phase 1\n",
    "\n",
    "In this section, explain how you verified your results. Did you calculate solutions by hand for small N? Did you create unit tests? Did you cross-reference your Quantum energy values against your Classical MTS results? Did you check known symmetries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f9095-095b-48eb-adee-d6955cdfa4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "def to_pm1(bits):\n",
    "    \"\"\"Convert iterable of 0/1 bits to ±1 numpy array.\"\"\"\n",
    "    return np.array([1 if b == 0 else -1 for b in bits], dtype=np.int8)\n",
    "\n",
    "def reverse_seq(s):\n",
    "    return s[::-1].copy()\n",
    "\n",
    "def flip_all(s):\n",
    "    return (-s).copy()\n",
    "\n",
    "# -------------------------\n",
    "# 1) Manual sanity check N=3\n",
    "# -------------------------\n",
    "# Example sequence s = [+1, +1, -1]\n",
    "# C1 = s1*s2 + s2*s3 = (1*1) + (1*-1) = 0\n",
    "# C2 = s1*s3 = (1*-1) = -1\n",
    "# E = C1^2 + C2^2 = 0^2 + (-1)^2 = 1\n",
    "s = np.array([1, 1, -1], dtype=np.int8)\n",
    "E_hand = 1\n",
    "E_code = compute_energy(s)\n",
    "print(\"Manual check N=3\")\n",
    "print(\"Sequence:\", s, \"Energy(hand):\", E_hand, \"Energy(code):\", E_code)\n",
    "assert E_code == E_hand, \"Manual energy check failed!\"\n",
    "print(\"✅ Manual check passed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49497cc6-744c-4152-802c-2b3856fd41a0",
   "metadata": {},
   "source": [
    "## LABS Symmetries (Invariances)\n",
    "\n",
    "The LABS energy is invariant under several transformations, which provide useful\n",
    "self-validation checks for verifying the correctness of the energy computation.\n",
    "\n",
    "### 1) Global Sign Flip\n",
    "\n",
    "Let \\(\\mathbf{s}' = -\\mathbf{s}\\), meaning \\(s'_i = -s_i\\). Then:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_k(\\mathbf{s}')\n",
    "&= \\sum_{i=1}^{N-k} s'_i s'_{i+k} \\\\\n",
    "&= \\sum_{i=1}^{N-k} (-s_i)(-s_{i+k}) \\\\\n",
    "&= \\sum_{i=1}^{N-k} s_i s_{i+k} \\\\\n",
    "&= C_k(\\mathbf{s}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "E(\\mathbf{s}') = E(\\mathbf{s}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Reversal Symmetry\n",
    "\n",
    "Let \\(\\mathbf{s}^{\\text{rev}}\\) denote the reversed sequence, defined by\n",
    "\\(s^{\\text{rev}}_i = s_{N+1-i}\\).\n",
    "\n",
    "Reversal does not change the multiset of pairwise products \\(s_i s_{i+k}\\) for\n",
    "each lag \\(k\\); it only reorders them. Thus:\n",
    "\n",
    "$$\n",
    "C_k(\\mathbf{s}^{\\text{rev}}) = C_k(\\mathbf{s}),\n",
    "$$\n",
    "\n",
    "which implies:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{s}^{\\text{rev}}) = E(\\mathbf{s}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Combined Reversal and Sign Flip\n",
    "\n",
    "Since both global sign flip and reversal individually preserve the LABS energy,\n",
    "their composition also leaves the energy invariant:\n",
    "\n",
    "$$\n",
    "E(-\\mathbf{s}^{\\text{rev}}) = E(\\mathbf{s}).\n",
    "$$\n",
    "\n",
    "Because these symmetries are guaranteed by the mathematical structure of the LABS\n",
    "objective, they act as strong invariance tests for validating our\n",
    "\\texttt{compute\\_energy} implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7edc46-d082-4b30-9816-d05bc5e37029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 2) Symmetry invariance tests for LABS\n",
    "# ----------------------------------------\n",
    "# LABS energy should be invariant under:\n",
    "# - global sign flip: s -> -s\n",
    "# - reversal: s -> reverse(s)\n",
    "# - reversal + sign flip\n",
    "\n",
    "def symmetry_tests(num_trials=200, N=20):\n",
    "    for _ in range(num_trials):\n",
    "        s = np.array([random.choice([-1, 1]) for _ in range(N)], dtype=np.int8)\n",
    "        E = compute_energy(s)\n",
    "\n",
    "        s_flip = flip_all(s)\n",
    "        s_rev  = reverse_seq(s)\n",
    "        s_both = flip_all(s_rev)\n",
    "\n",
    "        if compute_energy(s_flip) != E:\n",
    "            return False, \"flip invariance failed\"\n",
    "        if compute_energy(s_rev) != E:\n",
    "            return False, \"reverse invariance failed\"\n",
    "        if compute_energy(s_both) != E:\n",
    "            return False, \"reverse+flip invariance failed\"\n",
    "    return True, \"all symmetry tests passed\"\n",
    "\n",
    "ok, msg = symmetry_tests(num_trials=300, N=25)\n",
    "print(\"Symmetry tests:\", msg)\n",
    "assert ok, msg\n",
    "print(\"✅ Symmetry invariance passed.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5dcf5-a34f-4407-a37a-3abf27249da1",
   "metadata": {},
   "source": [
    "## Brute-Force Ground Truth for Small \\(N\\)\n",
    "\n",
    "For small sequence lengths \\(N\\), we can compute the global optimum exactly by\n",
    "enumerating all \\(2^N\\) possible sequences using the \\(\\pm 1\\) representation.\n",
    "\n",
    "$$\n",
    "\\{-1, +1\\}^N \\quad \\text{has size} \\quad 2^N.\n",
    "$$\n",
    "\n",
    "We compute the LABS energy \\(E(\\mathbf{s})\\) for every\n",
    "\\(\\mathbf{s} \\in \\{-1,+1\\}^N\\) and take:\n",
    "\n",
    "$$\n",
    "E^\\star(N) = \\min_{\\mathbf{s} \\in \\{-1,+1\\}^N} E(\\mathbf{s}).\n",
    "$$\n",
    "\n",
    "This provides an oracle (ground truth) for \\(N \\le 10\\) (and in practice up to\n",
    "\\(N \\le 12\\)), allowing us to verify that our Memetic Tabu Search (MTS)\n",
    "implementation can reach the true optimum when the search space is small enough\n",
    "to fully enumerate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ba5ef-5b1f-4b89-8934-336357710056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3) Brute-force ground truth (small N only)\n",
    "# ---------------------------------------------------\n",
    "def brute_force_labs(N):\n",
    "    \"\"\"\n",
    "    Enumerate all 2^N sequences (0/1), convert to ±1, compute energy, return optimum.\n",
    "    For N <= 10 this is fast enough in a notebook.\n",
    "    \"\"\"\n",
    "    best_E = None\n",
    "    best_s = None\n",
    "    for bits in itertools.product([0, 1], repeat=N):\n",
    "        s = to_pm1(bits)\n",
    "        E = compute_energy(s)\n",
    "        if best_E is None or E < best_E:\n",
    "            best_E = E\n",
    "            best_s = s.copy()\n",
    "    return best_s, best_E\n",
    "\n",
    "for N_small in [4, 5, 6, 7, 8, 9, 10]:\n",
    "    s_opt, E_opt = brute_force_labs(N_small)\n",
    "    print(\n",
    "        f\"N={N_small:2d} | \"\n",
    "        f\"Brute-force optimal energy (ground truth) = {E_opt:3d} | \"\n",
    "        f\"Example optimal sequence = {sequence_to_string(s_opt)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940f333-8fb9-4741-ba49-675bab8056b3",
   "metadata": {},
   "source": [
    "## Manual Sanity Check (Example for \\(N=3\\))\n",
    "\n",
    "To validate \\texttt{compute\\_energy}, we compute the LABS energy manually for a\n",
    "small sequence. Let:\n",
    "\n",
    "$$\n",
    "\\mathbf{s} = (s_1, s_2, s_3) = (+1, +1, -1).\n",
    "$$\n",
    "\n",
    "For \\(N=3\\), there are two lags: \\(k=1\\) and \\(k=2\\).\n",
    "\n",
    "### Lag \\(k=1\\)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_1\n",
    "&= s_1 s_2 + s_2 s_3 \\\\\n",
    "&= (1)(1) + (1)(-1) \\\\\n",
    "&= 1 - 1 = 0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Lag \\(k=2\\)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_2\n",
    "&= s_1 s_3 \\\\\n",
    "&= (1)(-1) = -1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the energy is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(\\mathbf{s})\n",
    "&= C_1^2 + C_2^2 \\\\\n",
    "&= 0^2 + (-1)^2 = 1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We confirm that our code returns \\(E(\\mathbf{s}) = 1\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ec451-0d9a-4b13-9b83-8e253f3ac820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 4) Check MTS reaches the brute-force optimum (small N)\n",
    "# ---------------------------------------------------\n",
    "def validate_mts_against_bruteforce(\n",
    "    N_list=(6, 7, 8, 9, 10),\n",
    "    population_size=30,\n",
    "    max_generations=200,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=200,\n",
    "    tabu_tenure=7,\n",
    "    trials=3\n",
    "):\n",
    "    \"\"\"\n",
    "    For each N, compute brute-force optimum and see whether MTS hits it within a few trials.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for N in N_list:\n",
    "        s_opt, E_opt = brute_force_labs(N)\n",
    "\n",
    "        hit = False\n",
    "        best_found = None\n",
    "        for t in range(trials):\n",
    "            best_seq, best_E, final_pop, hist = mts(\n",
    "                N=N,\n",
    "                population_size=population_size,\n",
    "                max_generations=max_generations,\n",
    "                p_mut=p_mut,\n",
    "                tabu_iter=tabu_iter,\n",
    "                tabu_tenure=tabu_tenure,\n",
    "                initial_population=None,\n",
    "                verbose=False\n",
    "            )\n",
    "            best_found = best_E if best_found is None else min(best_found, best_E)\n",
    "            if best_E == E_opt:\n",
    "                hit = True\n",
    "                break\n",
    "\n",
    "        results.append((N, E_opt, best_found, hit))\n",
    "        print(\n",
    "            f\"N={N:2d} | \"\n",
    "            f\"Brute-force optimal energy = {E_opt:3d} | \"\n",
    "            f\"Best MTS energy (over {trials} runs) = {best_found:3d} | \"\n",
    "            f\"Optimal reached = {hit}\"\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "_ = validate_mts_against_bruteforce(\n",
    "    N_list=(6, 7, 8, 9, 10),\n",
    "    population_size=30,\n",
    "    max_generations=250,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=250,\n",
    "    tabu_tenure=7,\n",
    "    trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf1b34-8149-4d1b-8dd4-aed87df2268c",
   "metadata": {},
   "source": [
    "## Hybrid Workflow: Quantum-Seeding for MTS\n",
    "\n",
    "The digitized counterdiabatic circuit prepares a quantum state of the form:\n",
    "\n",
    "$$\n",
    "\\lvert \\psi(\\theta) \\rangle = U(\\theta)\\lvert 0 \\rangle^{\\otimes N},\n",
    "$$\n",
    "\n",
    "which induces a measurement distribution over computational basis bitstrings.\n",
    "\n",
    "$$\n",
    "p_\\theta(x) = \\left|\\langle x \\mid \\psi(\\theta) \\rangle\\right|^2,\n",
    "\\quad x \\in \\{0,1\\}^N.\n",
    "$$\n",
    "\n",
    "Each measured bitstring \\(x\\) is converted into a LABS sequence\n",
    "\\(\\mathbf{s}(x) \\in \\{-1,+1\\}^N\\) using a fixed mapping\n",
    "(e.g., \\(0 \\mapsto +1\\), \\(1 \\mapsto -1\\)).\n",
    "These quantum samples provide an **informed initial population** for the\n",
    "Memetic Tabu Search (MTS).\n",
    "\n",
    "The classical optimizer then refines these candidates using recombination,\n",
    "mutation, and tabu search to reach low-energy LABS solutions.\n",
    "\n",
    "This hybrid approach does not replace classical optimization; rather, it\n",
    "modifies the **initial sampling distribution** of candidate solutions,\n",
    "potentially accelerating convergence to optimal or near-optimal sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa5a03-a80a-4b38-a5ac-18a263a28b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cudaq\n",
    "# Assumes these exist already:\n",
    "# - cudaq imported\n",
    "# - trotterized_circuit defined as trotterized_circuit(N, G2, G4, steps, thetas)\n",
    "# - N, G2, G4, n_steps, thetas defined\n",
    "# - compute_energy defined (LABS energy on ±1)\n",
    "#\n",
    "# If your compute_energy expects np.ndarray, we return np.ndarray below.\n",
    "\n",
    "def bitstring_to_pm1_array(bs: str) -> np.ndarray:\n",
    "    # 0 -> +1, 1 -> -1\n",
    "    return np.array([1 if b == \"0\" else -1 for b in bs], dtype=np.int8)\n",
    "\n",
    "def sample_quantum_sequences(shots: int):\n",
    "    \"\"\"\n",
    "    Samples the CUDA-Q kernel and returns:\n",
    "      - seqs: list[np.ndarray] of ±1 sequences\n",
    "      - counts_items: sorted list of (bitstring, count)\n",
    "    \"\"\"\n",
    "    # Robust shots arg\n",
    "    try:\n",
    "        counts = cudaq.sample(trotterized_circuit, N, G2, G4, n_steps, thetas, shots_count=shots)\n",
    "    except TypeError:\n",
    "        counts = cudaq.sample(trotterized_circuit, N, G2, G4, n_steps, thetas, shots=shots)\n",
    "\n",
    "    try:\n",
    "        items = list(counts.items())\n",
    "    except Exception:\n",
    "        items = list(dict(counts).items())\n",
    "\n",
    "    # Sort by frequency\n",
    "    items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Expand according to counts -> list of samples\n",
    "    seqs = []\n",
    "    for bs, ct in items:\n",
    "        if len(bs) != N:\n",
    "            # If formatting is weird (spaces/prefix), skip; tell me if you see this.\n",
    "            continue\n",
    "        seq = bitstring_to_pm1_array(bs)\n",
    "        seqs.extend([seq] * ct)\n",
    "\n",
    "    return seqs, items\n",
    "\n",
    "def sample_random_sequences(num_samples: int):\n",
    "    return [np.array([random.choice([-1, 1]) for _ in range(N)], dtype=np.int8) for _ in range(num_samples)]\n",
    "\n",
    "def energy_stats(seqs):\n",
    "    energies = np.array([compute_energy(s) for s in seqs], dtype=int)\n",
    "    return {\n",
    "        \"mean\": float(np.mean(energies)),\n",
    "        \"median\": float(np.median(energies)),\n",
    "        \"min\": int(np.min(energies)),\n",
    "        \"p10\": float(np.percentile(energies, 10)),\n",
    "        \"p25\": float(np.percentile(energies, 25)),\n",
    "        \"p75\": float(np.percentile(energies, 75)),\n",
    "        \"p90\": float(np.percentile(energies, 90)),\n",
    "        \"energies\": energies\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Run the validation\n",
    "# ----------------------------\n",
    "shots = 2000  # increase if runtime allows\n",
    "quantum_seqs, quantum_counts = sample_quantum_sequences(shots=shots)\n",
    "random_seqs = sample_random_sequences(num_samples=len(quantum_seqs))\n",
    "\n",
    "print(f\"Quantum samples collected: {len(quantum_seqs)} (from {shots} shots)\")\n",
    "print(f\"Unique outcomes: {len(quantum_counts)}\")\n",
    "print(\"Top 10 outcomes (bitstring: count):\")\n",
    "for bs, ct in quantum_counts[:10]:\n",
    "    print(f\"  {bs}: {ct}\")\n",
    "\n",
    "# If everything is \":1\", you’re still at effectively one-shot or very flat distribution.\n",
    "num_repeats = sum(1 for _, ct in quantum_counts if ct > 1)\n",
    "print(f\"Outcomes with count > 1: {num_repeats}\")\n",
    "\n",
    "qs = energy_stats(quantum_seqs)\n",
    "rs = energy_stats(random_seqs)\n",
    "\n",
    "print(\"\\nEnergy comparison (lower is better):\")\n",
    "print(f\"Quantum  mean={qs['mean']:.2f}, median={qs['median']:.2f}, min={qs['min']}, p10={qs['p10']:.2f}, p25={qs['p25']:.2f}\")\n",
    "print(f\"Random   mean={rs['mean']:.2f}, median={rs['median']:.2f}, min={rs['min']}, p10={rs['p10']:.2f}, p25={rs['p25']:.2f}\")\n",
    "\n",
    "# Best-of-K test (important for seeding)\n",
    "K = 50\n",
    "q_bestK = int(np.min(qs[\"energies\"][:K])) if len(qs[\"energies\"]) >= K else int(np.min(qs[\"energies\"]))\n",
    "r_bestK = int(np.min(rs[\"energies\"][:K])) if len(rs[\"energies\"]) >= K else int(np.min(rs[\"energies\"]))\n",
    "print(f\"\\nBest-of-{K} (first {K} samples): quantum={q_bestK}, random={r_bestK}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Quick visualization\n",
    "# ----------------------------\n",
    "plt.figure()\n",
    "plt.hist(qs[\"energies\"], bins=30, alpha=0.6, label=\"Quantum samples\")\n",
    "plt.hist(rs[\"energies\"], bins=30, alpha=0.6, label=\"Random samples\")\n",
    "plt.xlabel(\"LABS Energy\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"Energy distribution: Quantum vs Random (N={N}, shots={shots})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddebb83-5896-4bff-8718-2d1f06ee5d77",
   "metadata": {},
   "source": [
    "## Benchmarking and Performance Evaluation\n",
    "\n",
    "In this section, we benchmark the performance of the classical Memetic Tabu Search (MTS)\n",
    "under two different initialization strategies:\n",
    "\n",
    "1. **Random-seeded MTS**: the population is initialized uniformly at random.\n",
    "2. **Quantum-seeded MTS**: the initial population is seeded using measurement outcomes\n",
    "   from the digitized counterdiabatic quantum circuit implemented in Exercise 5.\n",
    "\n",
    "All other MTS hyperparameters are kept identical. This ensures a fair comparison where\n",
    "the only difference is the initialization strategy.\n",
    "\n",
    "We report:\n",
    "- best final energy achieved,\n",
    "- convergence behavior over generations,\n",
    "- and runtime statistics,\n",
    "averaged over multiple independent trials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa47149-3a35-472f-8e39-8b7ae1835156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitstring_to_pm1_array(bs: str) -> np.ndarray:\n",
    "    return np.array([1 if b == \"0\" else -1 for b in bs], dtype=np.int8)\n",
    "\n",
    "def build_quantum_seed_population(\n",
    "    N: int,\n",
    "    population_size: int,\n",
    "    shots: int,\n",
    "    n_steps: int,\n",
    "    T: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an initial population for MTS using quantum samples.\n",
    "    \"\"\"\n",
    "    # Interaction sets\n",
    "    G2, G4 = get_interactions(N)\n",
    "\n",
    "    # Compute thetas\n",
    "    dt = T / n_steps\n",
    "    thetas = []\n",
    "    for step in range(1, n_steps + 1):\n",
    "        t = step * dt\n",
    "        thetas.append(utils.compute_theta(t, dt, T, N, G2, G4))\n",
    "\n",
    "    # Sample the quantum circuit\n",
    "    try:\n",
    "        counts = cudaq.sample(\n",
    "            trotterized_circuit, N, G2, G4, n_steps, thetas, shots_count=shots\n",
    "        )\n",
    "    except TypeError:\n",
    "        counts = cudaq.sample(\n",
    "            trotterized_circuit, N, G2, G4, n_steps, thetas, shots=shots\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        items = list(counts.items())\n",
    "    except Exception:\n",
    "        items = list(dict(counts).items())\n",
    "\n",
    "    # Convert unique bitstrings to ±1 sequences\n",
    "    candidates = []\n",
    "    for bs, ct in items:\n",
    "        if len(bs) == N:\n",
    "            candidates.append(bitstring_to_pm1_array(bs))\n",
    "\n",
    "    # Rank by classical LABS energy\n",
    "    ranked = [(s, compute_energy(s)) for s in candidates]\n",
    "    ranked.sort(key=lambda x: x[1])\n",
    "\n",
    "    seed_pop = [s for s, _ in ranked[:population_size]]\n",
    "\n",
    "    # Fill remainder randomly if needed\n",
    "    while len(seed_pop) < population_size:\n",
    "        seed_pop.append(\n",
    "            np.array([random.choice([-1, 1]) for _ in range(N)], dtype=np.int8)\n",
    "        )\n",
    "\n",
    "    return seed_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b7684-ea8e-48ac-b316-fb6911d90ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_trial(\n",
    "    N: int,\n",
    "    population_size: int,\n",
    "    max_generations: int,\n",
    "    p_mut: float,\n",
    "    tabu_iter: int,\n",
    "    tabu_tenure: int,\n",
    "    seed: int,\n",
    "    quantum: bool,\n",
    "    shots: int = 2000,\n",
    "    n_steps: int = 1,\n",
    "    T: float = 1.0\n",
    "):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    initial_population = None\n",
    "    if quantum:\n",
    "        initial_population = build_quantum_seed_population(\n",
    "            N, population_size, shots, n_steps, T\n",
    "        )\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    best_seq, best_E, final_pop, history = mts(\n",
    "        N=N,\n",
    "        population_size=population_size,\n",
    "        max_generations=max_generations,\n",
    "        p_mut=p_mut,\n",
    "        tabu_iter=tabu_iter,\n",
    "        tabu_tenure=tabu_tenure,\n",
    "        initial_population=initial_population,\n",
    "        verbose=False\n",
    "    )\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    return {\n",
    "        \"N\": N,\n",
    "        \"quantum_seeded\": quantum,\n",
    "        \"best_E\": int(best_E),\n",
    "        \"runtime_s\": t1 - t0,\n",
    "        \"history\": history\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b70914-4003-4fca-b046-8c393681e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def benchmark(\n",
    "    N_list=(10, 12, 14, 16),\n",
    "    trials=5,\n",
    "    population_size=20,\n",
    "    max_generations=50,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=100,\n",
    "    tabu_tenure=7,\n",
    "    shots=2000,\n",
    "    n_steps=1,\n",
    "    T=1.0,\n",
    "    base_seed=123\n",
    "):\n",
    "    rows = []\n",
    "    histories = []\n",
    "\n",
    "    for N in N_list:\n",
    "        for t in range(trials):\n",
    "            seed = base_seed + 1000 * N + t\n",
    "\n",
    "            r = run_one_trial(\n",
    "                N, population_size, max_generations, p_mut,\n",
    "                tabu_iter, tabu_tenure, seed,\n",
    "                quantum=False\n",
    "            )\n",
    "            q = run_one_trial(\n",
    "                N, population_size, max_generations, p_mut,\n",
    "                tabu_iter, tabu_tenure, seed,\n",
    "                quantum=True, shots=shots, n_steps=n_steps, T=T\n",
    "            )\n",
    "\n",
    "            rows.append({k: r[k] for k in [\"N\", \"quantum_seeded\", \"best_E\", \"runtime_s\"]})\n",
    "            rows.append({k: q[k] for k in [\"N\", \"quantum_seeded\", \"best_E\", \"runtime_s\"]})\n",
    "            histories.extend([r, q])\n",
    "\n",
    "            print(\n",
    "                f\"N={N}, trial {t+1}/{trials} | \"\n",
    "                f\"random E={r['best_E']} | quantum E={q['best_E']}\"\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(rows), histories\n",
    "\n",
    "\n",
    "df_bench, histories = benchmark(\n",
    "    N_list=(10, 12, 14, 16),\n",
    "    trials=5\n",
    ")\n",
    "\n",
    "df_bench\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf7917-13fe-47f5-ba3b-337efc1f75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    df_bench\n",
    "    .groupby([\"N\", \"quantum_seeded\"])\n",
    "    .agg(\n",
    "        best_E_mean=(\"best_E\", \"mean\"),\n",
    "        best_E_median=(\"best_E\", \"median\"),\n",
    "        best_E_min=(\"best_E\", \"min\"),\n",
    "        runtime_mean=(\"runtime_s\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63555c6f-f014-41e7-acf5-d9cd97f5c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_curve(histories, N, quantum, max_gens):\n",
    "    curves = [h[\"history\"] for h in histories if h[\"N\"] == N and h[\"quantum_seeded\"] == quantum]\n",
    "    curves = [\n",
    "        c[:max_gens+1] if len(c) >= max_gens+1 else c + [c[-1]] * (max_gens+1 - len(c))\n",
    "        for c in curves\n",
    "    ]\n",
    "    return np.mean(np.array(curves), axis=0)\n",
    "\n",
    "max_gens = 50\n",
    "for N in sorted(df_bench[\"N\"].unique()):\n",
    "    plt.figure()\n",
    "    plt.plot(mean_curve(histories, N, False, max_gens), label=\"Random initialization\")\n",
    "    plt.plot(mean_curve(histories, N, True, max_gens), label=\"Quantum initialization\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Best energy so far (mean over trials)\")\n",
    "    plt.title(f\"Convergence comparison (N={N})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d305e-e84b-4dcf-afc3-5ab8fb91ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Benchmark targets (E_opt)\n",
    "# ----------------------------\n",
    "E_OPT = {\n",
    "    3: 1.0, 4: 2.0, 5: 2.0, 6: 5.0, 7: 3.0, 8: 8.0, 9: 6.0, 10: 13.0,\n",
    "    11: 5.0, 12: 14.0, 13: 3.0, 14: 22.0, 15: 14.0, 16: 24.0, 17: 21.0, 18: 27.0,\n",
    "    19: 20.0, 20: 36.0, 21: 22.0, 22: 44.0, 23: 38.0, 24: 42.0, 25: 46.0, 26: 58.0,\n",
    "    27: 42.0, 28: 62.0, 29: 60.0, 30: 67.0, 31: 72.0, 32: 68.0, 33: 79.0, 34: 87.0,\n",
    "    35: 86.0, 36: 104.0, 37: 110.0, 38: 118.0, 39: 134.0, 40: 132.0\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Energy-eval counter wrapper\n",
    "# ----------------------------\n",
    "class EnergyCounter:\n",
    "    def __init__(self, energy_fn):\n",
    "        self.energy_fn = energy_fn\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, s):\n",
    "        self.count += 1\n",
    "        return self.energy_fn(s)\n",
    "\n",
    "energy_counter = EnergyCounter(compute_energy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c02840-e591-44b5-a118-74fcc880530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def run_mts_to_target(\n",
    "    N,\n",
    "    target_E,\n",
    "    *,\n",
    "    population_size=20,\n",
    "    max_generations=200,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=100,\n",
    "    tabu_tenure=7,\n",
    "    initial_population=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      solved (bool),\n",
    "      best_energy (int),\n",
    "      evals (int)  # number of compute_energy calls (proxy for work)\n",
    "      wall_time (float)  # seconds\n",
    "      best_seq (np.ndarray)\n",
    "    \"\"\"\n",
    "    global compute_energy\n",
    "\n",
    "    # swap in the counting energy function\n",
    "    original_energy = compute_energy\n",
    "    compute_energy = energy_counter\n",
    "    energy_counter.reset()\n",
    "\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        best_seq, best_E, final_pop, hist = mts(\n",
    "            N=N,\n",
    "            population_size=population_size,\n",
    "            max_generations=max_generations,\n",
    "            p_mut=p_mut,\n",
    "            tabu_iter=tabu_iter,\n",
    "            tabu_tenure=tabu_tenure,\n",
    "            initial_population=initial_population,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        solved = (best_E <= target_E)\n",
    "        dt = time.time() - t0\n",
    "        evals = energy_counter.count\n",
    "\n",
    "        return solved, best_E, evals, dt, best_seq\n",
    "\n",
    "    finally:\n",
    "        # restore original energy function no matter what\n",
    "        compute_energy = original_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c799a5-fd3f-4fd9-b38f-b93b5ee8ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bitstring_to_pm1(bs: str):\n",
    "    # '0' -> +1, '1' -> -1\n",
    "    return np.array([1 if b == \"0\" else -1 for b in bs], dtype=int)\n",
    "\n",
    "def quantum_seed_population(\n",
    "    N, population_size, *,\n",
    "    shots=2000\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses your existing CUDA-Q setup:\n",
    "      - trotterized_circuit\n",
    "      - G2, G4, n_steps, thetas\n",
    "    Returns: List[np.ndarray] of length population_size\n",
    "    \"\"\"\n",
    "    # IMPORTANT: set shots explicitly so you don't get weird defaults\n",
    "    counts = cudaq.sample(trotterized_circuit, N, G2, G4, n_steps, thetas, shots_count=shots)\n",
    "\n",
    "    # extract (bitstring, count)\n",
    "    try:\n",
    "        items = list(counts.items())\n",
    "    except Exception:\n",
    "        items = list(dict(counts).items())\n",
    "\n",
    "    # unique bitstrings → candidate sequences\n",
    "    candidates = []\n",
    "    seen = set()\n",
    "    for bs, ct in items:\n",
    "        if bs not in seen:\n",
    "            seen.add(bs)\n",
    "            candidates.append(bitstring_to_pm1(bs))\n",
    "\n",
    "    # rank by classical energy (lower is better)\n",
    "    candidates.sort(key=compute_energy)\n",
    "\n",
    "    seed = candidates[:population_size]\n",
    "    while len(seed) < population_size:\n",
    "        seed.append(np.array([random.choice([-1, 1]) for _ in range(N)], dtype=int))\n",
    "\n",
    "    return seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5fb6f-8915-4761-ba01-627639b81f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def benchmark(\n",
    "    Ns,\n",
    "    trials=25,\n",
    "    *,\n",
    "    population_size=20,\n",
    "    max_generations=250,\n",
    "    p_mut=0.05,\n",
    "    tabu_iter=100,\n",
    "    tabu_tenure=7,\n",
    "    quantum_shots=2000,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for N in Ns:\n",
    "        target_E = E_OPT[N]\n",
    "        print(f\"\\n=== N={N}, target E={target_E} ===\")\n",
    "\n",
    "        for r in range(trials):\n",
    "            # ----- Classical MTS -----\n",
    "            solved, best_E, evals, dt, _ = run_mts_to_target(\n",
    "                N, target_E,\n",
    "                population_size=population_size,\n",
    "                max_generations=max_generations,\n",
    "                p_mut=p_mut,\n",
    "                tabu_iter=tabu_iter,\n",
    "                tabu_tenure=tabu_tenure,\n",
    "                initial_population=None,\n",
    "                verbose=False,\n",
    "            )\n",
    "            rows.append((\"MTS\", N, solved, best_E, evals, dt))\n",
    "\n",
    "            # ----- Quantum-seeded MTS (QE-MTS) -----\n",
    "            seed_pop = quantum_seed_population(N, population_size, shots=quantum_shots)\n",
    "            solved, best_E, evals, dt, _ = run_mts_to_target(\n",
    "                N, target_E,\n",
    "                population_size=population_size,\n",
    "                max_generations=max_generations,\n",
    "                p_mut=p_mut,\n",
    "                tabu_iter=tabu_iter,\n",
    "                tabu_tenure=tabu_tenure,\n",
    "                initial_population=seed_pop,\n",
    "                verbose=False,\n",
    "            )\n",
    "            rows.append((\"QE-MTS\", N, solved, best_E, evals, dt))\n",
    "\n",
    "        print(\"done.\")\n",
    "\n",
    "    return rows\n",
    "\n",
    "Ns = list(range(20, 30))   \n",
    "rows = benchmark(Ns, trials=3, max_generations=200, quantum_shots=1500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8246e3-d5ec-40b7-82e4-2762fee99f9a",
   "metadata": {},
   "source": [
    "## Benchmark Metric: Time-to-Solution (TTS)\n",
    "\n",
    "To study scaling behavior, we use a **Time-to-Solution (TTS)** metric consistent\n",
    "with the benchmarking protocol in the reference paper.\n",
    "\n",
    "For each problem size \\(N\\), let \\(E^\\star(N)\\) denote the **known optimal LABS\n",
    "energy**, obtained either from brute-force enumeration (for small \\(N\\)) or from\n",
    "published reference tables. A single run is considered **successful** if it\n",
    "produces some sequence \\(\\mathbf{s}\\) such that:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{s}) \\le E^\\star(N).\n",
    "$$\n",
    "\n",
    "We define the **Time-to-Solution** as the number of objective function evaluations\n",
    "required to reach the target energy **for the first time**. If \\(t\\) denotes the\n",
    "index of objective evaluations, then:\n",
    "\n",
    "$$\n",
    "\\text{TTS}(N) = \\min \\left\\{ t \\;:\\; E(\\mathbf{s}_t) \\le E^\\star(N) \\right\\}.\n",
    "$$\n",
    "\n",
    "In practice, we measure TTS using the number of calls to\n",
    "`compute_energy` (objective function evaluations), which is more\n",
    "hardware-independent than wall-clock time.\n",
    "\n",
    "We perform \\(R\\) independent runs for each value of \\(N\\) and report the **median**\n",
    "Time-to-Solution:\n",
    "\n",
    "$$\n",
    "\\text{Median-TTS}(N) =\n",
    "\\operatorname{median}\\left(\n",
    "\\text{TTS}_1(N), \\ldots, \\text{TTS}_R(N)\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "We plot Median-TTS versus \\(N\\) on a logarithmic scale to visualize the expected\n",
    "exponential scaling behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4058eb-6be7-4350-b2cb-2d15d731a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_benchmark(rows, use=\"evals\"):\n",
    "    # use=\"evals\" or use=\"time\"\n",
    "    idx = 4 if use == \"evals\" else 5\n",
    "\n",
    "    algs = sorted(set(r[0] for r in rows))\n",
    "    Ns = sorted(set(r[1] for r in rows))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for alg in algs:\n",
    "        # scatter all trials\n",
    "        for N in Ns:\n",
    "            vals = [r[idx] for r in rows if r[0]==alg and r[1]==N and r[2] is True]\n",
    "            # only plot solved trials (paper’s TTS is defined on success)\n",
    "            if len(vals):\n",
    "                plt.scatter([N]*len(vals), vals, alpha=0.35)\n",
    "\n",
    "        # median per N\n",
    "        med_x, med_y = [], []\n",
    "        for N in Ns:\n",
    "            vals = [r[idx] for r in rows if r[0]==alg and r[1]==N and r[2] is True]\n",
    "            if len(vals):\n",
    "                med_x.append(N)\n",
    "                med_y.append(np.median(vals))\n",
    "        plt.plot(med_x, med_y, linestyle=\"--\", marker=\"o\", label=alg)\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Sequence length (N)\")\n",
    "    ylabel = \"Median energy evaluations (proxy TTS)\" if use==\"evals\" else \"Median wall time (s)\"\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"Benchmark: QE-MTS vs MTS on LABS (solved trials only)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "plot_benchmark(rows, use=\"evals\")\n",
    "# plot_benchmark(rows, use=\"time\")  # if you also want seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616d101-6812-4da8-b536-652bfa0a503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_publication_style(rows):\n",
    "    # --- Settings for \"Exactly Like This\" ---\n",
    "    # Colors extracted from the original image\n",
    "    color_qe = '#2A9D8F'  # Teal for QE-MTS\n",
    "    color_mts = '#E76F51' # Salmon/Orange for MTS\n",
    "    \n",
    "    # Filter data\n",
    "    # rows format: (Algorithm, N, solved, best_E, evals, dt)\n",
    "    # We use index 4 (evals) as proxy for TTS, consistent with the 10^6 magnitude in the image\n",
    "    data_qe = {}\n",
    "    data_mts = {}\n",
    "    \n",
    "    Ns = sorted(list(set(r[1] for r in rows)))\n",
    "    \n",
    "    for N in Ns:\n",
    "        # Get successful runs for QE-MTS\n",
    "        vals_qe = [r[4] for r in rows if r[0] == 'QE-MTS' and r[1] == N and r[2]]\n",
    "        if vals_qe: data_qe[N] = vals_qe\n",
    "        \n",
    "        # Get successful runs for MTS\n",
    "        vals_mts = [r[4] for r in rows if r[0] == 'MTS' and r[1] == N and r[2]]\n",
    "        if vals_mts: data_mts[N] = vals_mts\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # --- Helper to plot Violin + Scatter + Median ---\n",
    "    def plot_group_style(data_dict, color, label_base, shift):\n",
    "        x_vals = sorted(data_dict.keys())\n",
    "        y_arrays = [data_dict[x] for x in x_vals]\n",
    "        \n",
    "        # 1. Violin Plot (The shaded distribution background)\n",
    "        parts = ax.violinplot(y_arrays, positions=x_vals, showmeans=False, showextrema=False, widths=0.6)\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor(color)\n",
    "            pc.set_alpha(0.3)\n",
    "            \n",
    "        # 2. Scatter Points (The dots)\n",
    "        for x in x_vals:\n",
    "            y = data_dict[x]\n",
    "            # Add small random jitter to x for visibility\n",
    "            jitter = np.random.normal(0, 0.04, size=len(y))\n",
    "            ax.scatter(np.array([x]*len(y)) + jitter, y, color=color, s=20, alpha=0.6, edgecolors='none')\n",
    "            \n",
    "            # 3. Median Bar (The thick black horizontal line)\n",
    "            median_val = np.median(y)\n",
    "            ax.hlines(median_val, x - 0.1, x + 0.1, color='black', linewidth=2, zorder=10)\n",
    "\n",
    "        # 4. Trend Line (The dashed line)\n",
    "        # We fit log10(y) = slope * N + intercept\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        for x, ys in data_dict.items():\n",
    "            all_x.extend([x] * len(ys))\n",
    "            all_y.extend(ys)\n",
    "            \n",
    "        slope, intercept, _, _, _ = linregress(all_x, np.log10(all_y))\n",
    "        \n",
    "        # Calculate scaling factor for the label (e.g. 1.24^N)\n",
    "        # slope = log10(base), so base = 10^slope\n",
    "        scaling_base = 10**slope\n",
    "        \n",
    "        # Generate line points\n",
    "        line_x = np.linspace(min(x_vals), max(x_vals), 100)\n",
    "        line_y = 10**(slope * line_x + intercept)\n",
    "        \n",
    "        ax.plot(line_x, line_y, color=color, linestyle='--', linewidth=3, label=f\"{label_base} ($\\sim {scaling_base:.2f}^N$)\")\n",
    "\n",
    "    # --- Plot Both Groups ---\n",
    "    if data_qe:\n",
    "        plot_group_style(data_qe, color_qe, \"QE-MTS\", 0)\n",
    "    if data_mts:\n",
    "        plot_group_style(data_mts, color_mts, \"MTS\", 0)\n",
    "\n",
    "    # --- Visual Styling to Match Screenshot ---\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # Ticks and Labels\n",
    "    ax.set_xticks(Ns)\n",
    "    ax.set_xticklabels(Ns, rotation=45, fontsize=12)\n",
    "    ax.set_xlabel('Sequence length ($N$)', fontsize=14)\n",
    "    ax.set_ylabel('Median Time-to-Solution (TTS)', fontsize=14)\n",
    "    \n",
    "    # Legend (Top Left, transparent background)\n",
    "    legend = ax.legend(loc='upper left', frameon=False, fontsize=14)\n",
    "    \n",
    "    # Grid lines (Light horizontal line at 10^6)\n",
    "    ax.axhline(10**6, color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Border thickness\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run this function using the 'rows' variable from your previous benchmark cells\n",
    "plot_publication_style(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
